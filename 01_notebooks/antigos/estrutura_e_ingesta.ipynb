{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montar ou identificar os diretórios locais, Persistir em um Postgres os dados em Silver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Google Drive detectado localmente em: G:\\\\Drives compartilhados\n",
      "IN_COLAB = False\n",
      "DRIVE_ROOT = G:\\\\Drives compartilhados\n",
      "SHARED_DRIVES = G:\\Drives compartilhados\n"
     ]
    }
   ],
   "source": [
    "# Montar Google Drive (Colab) ou detectar Google Drive Desktop (local)\n",
    "# - Em Colab: monta em /content/drive\n",
    "# - Local (Windows): usa Google Drive for Desktop (ex.: G:\\Drives compartilhados)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    from google.colab import drive as _gdrive  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "DRIVE_ROOT = None  # caminho raiz do Drive\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Monta o Google Drive no Colab\n",
    "    _gdrive.mount('/content/drive', force_remount=False)\n",
    "    DRIVE_ROOT = '/content/drive'\n",
    "    print(f\"[OK] Google Drive montado no Colab em: {DRIVE_ROOT}\")\n",
    "else:\n",
    "    # Detecta Google Drive for Desktop no Windows\n",
    "    candidates = [\n",
    "        r'G:\\\\Drives compartilhados',   # PT-BR: Shared drives\n",
    "        r'G:\\\\Shared drives',           # EN: Shared drives\n",
    "        r'G:\\\\My Drive',                # EN: Meu Drive (conta pessoal)\n",
    "        os.path.expandvars(r'%USERPROFILE%\\\\Google Drive'),  # legado\n",
    "        os.path.expandvars(r'%USERPROFILE%\\\\Google Drive (Shared drives)'),\n",
    "    ]\n",
    "    DRIVE_ROOT = next((p for p in candidates if os.path.exists(p)), None)\n",
    "    if DRIVE_ROOT:\n",
    "        print(f\"[OK] Google Drive detectado localmente em: {DRIVE_ROOT}\")\n",
    "    else:\n",
    "        print('[AVISO] Google Drive não encontrado automaticamente.\\n'\n",
    "              '       Verifique se o Google Drive for Desktop está instalado e o caminho correto (ex.: G:\\\\Drives compartilhados).')\n",
    "\n",
    "# Variáveis úteis para uso posterior\n",
    "SHARED_DRIVES = str(Path(DRIVE_ROOT) if DRIVE_ROOT else '')\n",
    "print('IN_COLAB =', IN_COLAB)\n",
    "print('DRIVE_ROOT =', DRIVE_ROOT)\n",
    "print('SHARED_DRIVES =', SHARED_DRIVES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 31 arquivos parquet em G:\\Drives compartilhados\\BOLSA_2026\\a_bolsa2026_gemini\\00_data\\01_raw\n",
      "\n",
      "Erros de leitura:\n",
      "Nenhum erro\n",
      "\n",
      "Colunas comuns (presentes em todos):\n",
      "['Adj Close', 'Close', 'Date', 'Dividends', 'High', 'Low', 'Open', 'Stock Splits', 'Volume']\n",
      "\n",
      "Tipos por coluna (top-1):\n",
      "- Adj Close: double (freq 31/31)\n",
      "- Capital Gains: double (freq 1/31)\n",
      "- Close: double (freq 31/31)\n",
      "- Date: timestamp[ns, tz=America/Sao_Paulo] (freq 25/31)\n",
      "- Dividends: double (freq 31/31)\n",
      "- High: double (freq 31/31)\n",
      "- Low: double (freq 31/31)\n",
      "- Open: double (freq 31/31)\n",
      "- Stock Splits: double (freq 31/31)\n",
      "- Volume: int64 (freq 31/31)\n",
      "\n",
      "Amostras de valores (primeiras 5 linhas) para 2 arquivos:\n",
      "\n",
      "== _bvsp_ohlcv_actions_20120101_20250922.parquet (linhas=3400) ==\n",
      "  Open: [57836.0, 59263.0, 59354.0, 58565.0, 58601.0]\n",
      "  High: [59288.0, 59519.0, 59354.0, 59261.0, 59220.0]\n",
      "  Low: [57836.0, 58558.0, 57963.0, 58355.0, 58599.0]\n",
      "  Close: [59265.0, 59365.0, 58546.0, 58600.0, 59083.0]\n",
      "  Adj Close: [59265.0, 59365.0, 58546.0, 58600.0, 59083.0]\n",
      "  Volume: [3083000, 2252000, 2351200, 1659200, 2244600]\n",
      "  Dividends: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Stock Splits: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Date: [Timestamp('2012-01-03 00:00:00-0200', tz='America/Sao_Paulo'), Timestamp('2012-01-04 00:00:00-0200', tz='America/Sao_Paulo'), Timestamp('2012-01-05 00:00:00-0200', tz='America/Sao_Paulo'), Timestamp('2012-01-06 00:00:00-0200', tz='America/Sao_Paulo'), Timestamp('2012-01-09 00:00:00-0200', tz='America/Sao_Paulo')]\n",
      "\n",
      "== _gspc_ohlcv_actions_20120101_20250922.parquet (linhas=3449) ==\n",
      "  Open: [1258.8599853515625, 1277.030029296875, 1277.300048828125, 1280.9300537109375, 1277.8299560546875]\n",
      "  High: [1284.6199951171875, 1278.72998046875, 1283.050048828125, 1281.8399658203125, 1281.989990234375]\n",
      "  Low: [1258.8599853515625, 1268.0999755859375, 1265.260009765625, 1273.3399658203125, 1274.550048828125]\n",
      "  Close: [1277.06005859375, 1277.300048828125, 1281.06005859375, 1277.81005859375, 1280.699951171875]\n",
      "  Adj Close: [1277.06005859375, 1277.300048828125, 1281.06005859375, 1277.81005859375, 1280.699951171875]\n",
      "  Volume: [3943710000, 3592580000, 4315950000, 3656830000, 3371600000]\n",
      "  Dividends: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Stock Splits: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Date: [Timestamp('2012-01-03 00:00:00-0500', tz='America/New_York'), Timestamp('2012-01-04 00:00:00-0500', tz='America/New_York'), Timestamp('2012-01-05 00:00:00-0500', tz='America/New_York'), Timestamp('2012-01-06 00:00:00-0500', tz='America/New_York'), Timestamp('2012-01-09 00:00:00-0500', tz='America/New_York')]\n"
     ]
    }
   ],
   "source": [
    "# Verificar parquet em 00_data/01_raw e resumir esquema\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "RAW_DIR = Path('G:/Drives compartilhados/BOLSA_2026/a_bolsa2026_gemini/00_data/01_raw')\n",
    "assert RAW_DIR.exists(), f\"Diretório não encontrado: {RAW_DIR}\"\n",
    "\n",
    "# Garantir pyarrow para leitura robusta\n",
    "try:\n",
    "    import pyarrow.parquet as pq\n",
    "    import pyarrow as pa\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pyarrow'])\n",
    "    import pyarrow.parquet as pq\n",
    "    import pyarrow as pa\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "files = sorted([p for p in RAW_DIR.glob('*.parquet')])\n",
    "print(f\"Encontrados {len(files)} arquivos parquet em {RAW_DIR}\")\n",
    "\n",
    "schemas = {}\n",
    "errors = {}\n",
    "row_counts = {}\n",
    "example_values = defaultdict(dict)\n",
    "\n",
    "for p in files:\n",
    "    try:\n",
    "        meta = pq.ParquetFile(p)\n",
    "        schema = meta.schema_arrow\n",
    "        schemas[p.name] = schema\n",
    "        row_counts[p.name] = meta.metadata.num_rows\n",
    "        # coletar alguns valores de exemplo das primeiras 5 linhas\n",
    "        table = meta.read_row_groups([0], columns=[f.name for f in schema]) if meta.metadata.num_row_groups>0 else meta.read()\n",
    "        head = table.slice(0, min(5, table.num_rows))\n",
    "        for f in schema:\n",
    "            col = head.column(f.name) if f.name in head.column_names else None\n",
    "            if col is not None:\n",
    "                vals = col.to_pylist()\n",
    "                example_values[p.name][f.name] = vals\n",
    "    except Exception as e:\n",
    "        errors[p.name] = str(e)\n",
    "\n",
    "# Determinar colunas comuns e tipos\n",
    "all_columns = [set(s.names) for s in schemas.values()]\n",
    "common_cols = set.intersection(*all_columns) if all_columns else set()\n",
    "\n",
    "# mapa de tipos por coluna (contagem)\n",
    "col_type_counter = defaultdict(Counter)\n",
    "for fname, schema in schemas.items():\n",
    "    for f in schema:\n",
    "        col_type_counter[f.name][str(f.type)] += 1\n",
    "\n",
    "print(\"\\nErros de leitura:\")\n",
    "if errors:\n",
    "    for k,v in errors.items():\n",
    "        print(f\"- {k}: {v}\")\n",
    "else:\n",
    "    print(\"Nenhum erro\")\n",
    "\n",
    "print(\"\\nColunas comuns (presentes em todos):\")\n",
    "print(sorted(common_cols))\n",
    "\n",
    "print(\"\\nTipos por coluna (top-1):\")\n",
    "for col, counter in sorted(col_type_counter.items()):\n",
    "    top = counter.most_common(1)[0]\n",
    "    print(f\"- {col}: {top[0]} (freq {top[1]}/{len(schemas)})\")\n",
    "\n",
    "print(\"\\nAmostras de valores (primeiras 5 linhas) para 2 arquivos:\")\n",
    "for fname in list(schemas.keys())[:2]:\n",
    "    print(f\"\\n== {fname} (linhas={row_counts.get(fname)}) ==\")\n",
    "    samples = example_values.get(fname, {})\n",
    "    for col, vals in list(samples.items())[:10]:\n",
    "        print(f\"  {col}: {vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"file_count\": 31,\n",
      "  \"error_count\": 0,\n",
      "  \"error_files\": [],\n",
      "  \"has_ohlcv_actions_pattern\": 31,\n",
      "  \"sample_files\": [\n",
      "    \"_bvsp_ohlcv_actions_20120101_20250922.parquet\",\n",
      "    \"_gspc_ohlcv_actions_20120101_20250922.parquet\",\n",
      "    \"_tnx_ohlcv_actions_20120101_20250922.parquet\",\n",
      "    \"_vix_ohlcv_actions_20120101_20250922.parquet\",\n",
      "    \"abev3_sa_ohlcv_actions_20120101_20250922.parquet\"\n",
      "  ],\n",
      "  \"common_columns\": [\n",
      "    \"Adj Close\",\n",
      "    \"Close\",\n",
      "    \"Date\",\n",
      "    \"Dividends\",\n",
      "    \"High\",\n",
      "    \"Low\",\n",
      "    \"Open\",\n",
      "    \"Stock Splits\",\n",
      "    \"Volume\"\n",
      "  ],\n",
      "  \"common_columns_types\": {\n",
      "    \"Adj Close\": {\n",
      "      \"type\": \"double\",\n",
      "      \"freq\": 31,\n",
      "      \"total\": 31\n",
      "    },\n",
      "    \"Close\": {\n",
      "      \"type\": \"double\",\n",
      "      \"freq\": 31,\n",
      "      \"total\": 31\n",
      "    },\n",
      "    \"Date\": {\n",
      "      \"type\": \"timestamp[ns, tz=America/Sao_Paulo]\",\n",
      "      \"freq\": 25,\n",
      "      \"total\": 31\n",
      "    },\n",
      "    \"Dividends\": {\n",
      "      \"type\": \"double\",\n",
      "      \"freq\": 31,\n",
      "      \"total\": 31\n",
      "    },\n",
      "    \"High\": {\n",
      "      \"type\": \"double\",\n",
      "      \"freq\": 31,\n",
      "      \"total\": 31\n",
      "    },\n",
      "    \"Low\": {\n",
      "      \"type\": \"double\",\n",
      "      \"freq\": 31,\n",
      "      \"total\": 31\n",
      "    },\n",
      "    \"Open\": {\n",
      "      \"type\": \"double\",\n",
      "      \"freq\": 31,\n",
      "      \"total\": 31\n",
      "    },\n",
      "    \"Stock Splits\": {\n",
      "      \"type\": \"double\",\n",
      "      \"freq\": 31,\n",
      "      \"total\": 31\n",
      "    },\n",
      "    \"Volume\": {\n",
      "      \"type\": \"int64\",\n",
      "      \"freq\": 31,\n",
      "      \"total\": 31\n",
      "    }\n",
      "  },\n",
      "  \"sample_columns_by_file\": {\n",
      "    \"_bvsp_ohlcv_actions_20120101_20250922.parquet\": [\n",
      "      \"Open\",\n",
      "      \"High\",\n",
      "      \"Low\",\n",
      "      \"Close\",\n",
      "      \"Adj Close\",\n",
      "      \"Volume\",\n",
      "      \"Dividends\",\n",
      "      \"Stock Splits\",\n",
      "      \"Date\"\n",
      "    ],\n",
      "    \"_gspc_ohlcv_actions_20120101_20250922.parquet\": [\n",
      "      \"Open\",\n",
      "      \"High\",\n",
      "      \"Low\",\n",
      "      \"Close\",\n",
      "      \"Adj Close\",\n",
      "      \"Volume\",\n",
      "      \"Dividends\",\n",
      "      \"Stock Splits\",\n",
      "      \"Date\"\n",
      "    ]\n",
      "  },\n",
      "  \"name_patterns_counts\": {\n",
      "    \"_sa_\": 24,\n",
      "    \"_nyb_\": 0,\n",
      "    \"_metadata_\": 0,\n",
      "    \"_ohlcv_actions_\": 31\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Resumo compacto (JSON) das estruturas parquet\n",
    "import json, re\n",
    "\n",
    "def top_types_for(cols):\n",
    "    out = {}\n",
    "    for c in cols:\n",
    "        cnt = col_type_counter.get(c, None)\n",
    "        if cnt:\n",
    "            t, n = cnt.most_common(1)[0]\n",
    "            out[c] = {\"type\": t, \"freq\": n, \"total\": len(schemas)}\n",
    "    return out\n",
    "\n",
    "summary = {}\n",
    "summary[\"file_count\"] = len(files)\n",
    "summary[\"error_count\"] = len(errors)\n",
    "summary[\"error_files\"] = sorted(list(errors.keys()))[:5]\n",
    "summary[\"has_ohlcv_actions_pattern\"] = sum(1 for p in files if \"_ohlcv_actions_\" in p.name)\n",
    "\n",
    "names = [p.name for p in files]\n",
    "summary[\"sample_files\"] = names[:5]\n",
    "\n",
    "# Colunas comuns e tipos\n",
    "cc = sorted(list(common_cols))\n",
    "summary[\"common_columns\"] = cc\n",
    "summary[\"common_columns_types\"] = top_types_for(cc)\n",
    "\n",
    "# Amostra de colunas de 2 arquivos\n",
    "sample_cols = {}\n",
    "for fname in names[:2]:\n",
    "    sch = schemas.get(fname)\n",
    "    if sch:\n",
    "        sample_cols[fname] = sch.names\n",
    "summary[\"sample_columns_by_file\"] = sample_cols\n",
    "\n",
    "# Padrões por nome: conta tags tipo '_sa_', '_nyb_', etc\n",
    "patterns = {\n",
    "    \"_sa_\": sum(1 for n in names if \"_sa_\" in n),\n",
    "    \"_nyb_\": sum(1 for n in names if \"_nyb_\" in n),\n",
    "    \"_metadata_\": sum(1 for n in names if \"_metadata_\" in n),\n",
    "    \"_ohlcv_actions_\": sum(1 for n in names if \"_ohlcv_actions_\" in n),\n",
    "}\n",
    "summary[\"name_patterns_counts\"] = patterns\n",
    "\n",
    "print(json.dumps(summary, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos a ajustar (esperados 6): 6\n",
      "- _gspc_ohlcv_actions_20120101_20250922.parquet\n",
      "- _tnx_ohlcv_actions_20120101_20250922.parquet\n",
      "- _vix_ohlcv_actions_20120101_20250922.parquet\n",
      "- bz=f_ohlcv_actions_20120101_20250922.parquet\n",
      "- dx-y.nyb_ohlcv_actions_20120101_20250922.parquet\n",
      "- ewz_ohlcv_actions_20120101_20250922.parquet\n",
      "Ajustados e salvos: 6 em G:\\Drives compartilhados\\BOLSA_2026\\a_bolsa2026_gemini\\00_data\\02_processed\n",
      "  -> _gspc_ohlcv_actions_20120101_20250922.parquet\n",
      "  -> _tnx_ohlcv_actions_20120101_20250922.parquet\n",
      "  -> _vix_ohlcv_actions_20120101_20250922.parquet\n",
      "  -> bz=f_ohlcv_actions_20120101_20250922.parquet\n",
      "  -> dx-y.nyb_ohlcv_actions_20120101_20250922.parquet\n",
      "  -> ewz_ohlcv_actions_20120101_20250922.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_22572\\2409226319.py:69: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if pd.api.types.is_datetime64tz_dtype(d):\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_22572\\2409226319.py:69: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if pd.api.types.is_datetime64tz_dtype(d):\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_22572\\2409226319.py:69: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if pd.api.types.is_datetime64tz_dtype(d):\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_22572\\2409226319.py:69: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if pd.api.types.is_datetime64tz_dtype(d):\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_22572\\2409226319.py:69: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if pd.api.types.is_datetime64tz_dtype(d):\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_22572\\2409226319.py:69: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if pd.api.types.is_datetime64tz_dtype(d):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificação: 6/6 com Date em tz=America/Sao_Paulo\n"
     ]
    }
   ],
   "source": [
    "# Ajustar timezone para America/Sao_Paulo nos 6 arquivos divergentes e salvar em 00_data/02_processed\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "RAW_DIR = Path('G:/Drives compartilhados/BOLSA_2026/a_bolsa2026_gemini/00_data/01_raw')\n",
    "PROC_DIR = Path('G:/Drives compartilhados/BOLSA_2026/a_bolsa2026_gemini/00_data/02_processed')\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Utilizar resultados computados previamente (schemas, files) se existirem no kernel; caso contrário, recomputar leve\n",
    "try:\n",
    "    files\n",
    "    schemas\n",
    "except NameError:\n",
    "    from collections import Counter, defaultdict\n",
    "    import pyarrow.parquet as pq\n",
    "    files = sorted([p for p in RAW_DIR.glob('*.parquet')])\n",
    "    schemas = {}\n",
    "    for p in files:\n",
    "        meta = pq.ParquetFile(p)\n",
    "        schemas[p.name] = meta.schema_arrow\n",
    "\n",
    "# Identificar quais não têm tz America/Sao_Paulo\n",
    "not_sp = []\n",
    "for p in files:\n",
    "    sch = schemas.get(p.name)\n",
    "    if not sch:\n",
    "        continue\n",
    "    if 'Date' in sch.names:\n",
    "        f = next((f for f in sch if f.name == 'Date'), None)\n",
    "        t = str(f.type) if f else ''\n",
    "        if 'timestamp' in t and 'tz=America/Sao_Paulo' in t:\n",
    "            continue\n",
    "        if 'timestamp' in t:\n",
    "            not_sp.append(p)\n",
    "    else:\n",
    "        # Pode estar como index no parquet (sem coluna explícita)\n",
    "        not_sp.append(p)\n",
    "\n",
    "print(f\"Arquivos a ajustar (esperados 6): {len(not_sp)}\")\n",
    "for p in not_sp:\n",
    "    print('-', p.name)\n",
    "\n",
    "# Função de ajuste: garantir Date com tz America/Sao_Paulo\n",
    "import pytz\n",
    "sp_tz = pytz.timezone('America/Sao_Paulo')\n",
    "\n",
    "fixed = []\n",
    "for p in not_sp:\n",
    "    df = pd.read_parquet(p)  # pandas com pyarrow engine\n",
    "\n",
    "    # Descobrir a coluna/índice de data\n",
    "    date_col = None\n",
    "    for cand in ['Date', 'date', 'DATE', 'Datetime', 'datetime', 'Timestamp', 'timestamp']:\n",
    "        if cand in df.columns:\n",
    "            date_col = cand\n",
    "            break\n",
    "    if date_col is None:\n",
    "        # Tentar índice\n",
    "        if isinstance(df.index, pd.DatetimeIndex):\n",
    "            df = df.reset_index().rename(columns={'index':'Date'})\n",
    "            date_col = 'Date'\n",
    "        else:\n",
    "            print(f\"[SKIP] Sem coluna/índice de data reconhecida: {p.name}\")\n",
    "            continue\n",
    "\n",
    "    d = pd.to_datetime(df[date_col], errors='coerce', utc=False)\n",
    "\n",
    "    if pd.api.types.is_datetime64tz_dtype(d):\n",
    "        # já tem tz, converter\n",
    "        df[date_col] = d.dt.tz_convert('America/Sao_Paulo')\n",
    "    else:\n",
    "        # naive -> assumir horário local SP\n",
    "        df[date_col] = d.dt.tz_localize('America/Sao_Paulo')\n",
    "\n",
    "    # Garantir nome padronizado 'Date'\n",
    "    if date_col != 'Date':\n",
    "        df = df.rename(columns={date_col: 'Date'})\n",
    "\n",
    "    out_path = PROC_DIR / p.name\n",
    "    df.to_parquet(out_path, engine='pyarrow', index=False)\n",
    "    fixed.append(out_path)\n",
    "\n",
    "print(f\"Ajustados e salvos: {len(fixed)} em {PROC_DIR}\")\n",
    "for q in fixed:\n",
    "    print('  ->', q.name)\n",
    "\n",
    "# Verificar tipos após escrita\n",
    "import pyarrow.parquet as pq\n",
    "ok = 0\n",
    "for q in fixed:\n",
    "    meta = pq.ParquetFile(q)\n",
    "    sch = meta.schema_arrow\n",
    "    f = next((f for f in sch if f.name == 'Date'), None)\n",
    "    if f and 'tz=America/Sao_Paulo' in str(f.type):\n",
    "        ok += 1\n",
    "print(f\"Verificação: {ok}/{len(fixed)} com Date em tz=America/Sao_Paulo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total arquivos a processar: 31\n",
      "Gravados 31 arquivos em G:\\Drives compartilhados\\BOLSA_2026\\a_bolsa2026_gemini\\00_data\\02_processed\n",
      "OK_COLS = True\n",
      "OK_TZ_SP = True\n"
     ]
    }
   ],
   "source": [
    "# Padronizar camada SILVER: schema consistente, tz America/Sao_Paulo, coluna Symbol, salvar em 00_data/02_processed\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "RAW_DIR = Path('G:/Drives compartilhados/BOLSA_2026/a_bolsa2026_gemini/00_data/01_raw')\n",
    "SILVER_DIR = Path('G:/Drives compartilhados/BOLSA_2026/a_bolsa2026_gemini/00_data/02_processed')\n",
    "SILVER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Lista alvo de colunas na ordem final\n",
    "TARGET_COLS = ['Symbol','Date','Open','High','Low','Close','Adj Close','Volume','Dividends','Stock Splits']\n",
    "\n",
    "# Extrair símbolo a partir do nome do arquivo\n",
    "# Exemplos: \"abev3_sa_ohlcv_actions_...\", \"_gspc_ohlcv_actions_...\"\n",
    "# Regra: pegar token inicial até o primeiro \"_ohlcv_actions_\"; remover prefixo '_' se houver; manter sufixo de mercado (ex.: _sa_)\n",
    "SYMBOL_RE = re.compile(r\"^(.*?)_ohlcv_actions_\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "def infer_symbol(fname: str) -> str:\n",
    "    m = SYMBOL_RE.match(fname)\n",
    "    raw = m.group(1) if m else fname.split('.')[0]\n",
    "    # normalizar: tirar duplicidade de underscores, remover prefixo '_'\n",
    "    raw = raw.lstrip('_')\n",
    "    return raw.lower()\n",
    "\n",
    "\n",
    "def ensure_tz_sp(s: pd.Series) -> pd.Series:\n",
    "    s = pd.to_datetime(s, errors='coerce', utc=False)\n",
    "    if isinstance(s.dtype, pd.DatetimeTZDtype):\n",
    "        return s.dt.tz_convert('America/Sao_Paulo')\n",
    "    else:\n",
    "        return s.dt.tz_localize('America/Sao_Paulo')\n",
    "\n",
    "\n",
    "files = sorted(RAW_DIR.glob('*.parquet'))\n",
    "print(f\"Total arquivos a processar: {len(files)}\")\n",
    "\n",
    "written = []\n",
    "for p in files:\n",
    "    df = pd.read_parquet(p)\n",
    "\n",
    "    # Descobrir/Padronizar Date\n",
    "    date_col = None\n",
    "    for cand in ['Date','date','DATE','Datetime','datetime','Timestamp','timestamp']:\n",
    "        if cand in df.columns:\n",
    "            date_col = cand\n",
    "            break\n",
    "    if date_col is None and isinstance(df.index, pd.DatetimeIndex):\n",
    "        df = df.reset_index().rename(columns={'index':'Date'})\n",
    "        date_col = 'Date'\n",
    "    if date_col is None:\n",
    "        print(f\"[SKIP] {p.name}: sem coluna/índice de data.\")\n",
    "        continue\n",
    "\n",
    "    # Tipos numéricos / faltantes\n",
    "    for col in ['Open','High','Low','Close','Adj Close','Volume','Dividends','Stock Splits']:\n",
    "        if col in df.columns:\n",
    "            if col == 'Volume':\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')  # permitir NA, salva como int64 no parquet\n",
    "            else:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').astype('float64')\n",
    "        else:\n",
    "            # coluna ausente vira NA\n",
    "            df[col] = pd.Series([pd.NA]*len(df)) if col=='Volume' else pd.Series([float('nan')]*len(df))\n",
    "\n",
    "    # Garantir timezone America/Sao_Paulo\n",
    "    df[date_col] = ensure_tz_sp(df[date_col])\n",
    "    if date_col != 'Date':\n",
    "        df = df.rename(columns={date_col: 'Date'})\n",
    "\n",
    "    # Adicionar Symbol\n",
    "    symbol = infer_symbol(p.name)\n",
    "    df.insert(0, 'Symbol', symbol)\n",
    "\n",
    "    # Reordenar colunas\n",
    "    missing = [c for c in TARGET_COLS if c not in df.columns]\n",
    "    for c in missing:\n",
    "        if c == 'Volume' and c not in df.columns:\n",
    "            df[c] = pd.Series([pd.NA]*len(df))\n",
    "        elif c not in df.columns:\n",
    "            df[c] = float('nan')\n",
    "    df = df[TARGET_COLS]\n",
    "\n",
    "    # Escrever com pyarrow, mantendo tz na Date\n",
    "    out = SILVER_DIR / p.name\n",
    "    df.to_parquet(out, engine='pyarrow', index=False)\n",
    "    written.append(out)\n",
    "\n",
    "print(f\"Gravados {len(written)} arquivos em {SILVER_DIR}\")\n",
    "\n",
    "# Verificação: todos com schema idêntico e tz correta\n",
    "schemas = []\n",
    "for q in written:\n",
    "    meta = pq.ParquetFile(q)\n",
    "    sch = meta.schema_arrow\n",
    "    schemas.append((q.name, sch))\n",
    "\n",
    "# verificar nomes/ordem das colunas\n",
    "ok_cols = all(s.names == TARGET_COLS for _, s in schemas)\n",
    "# verificar tz da Date\n",
    "ok_tz = all('tz=America/Sao_Paulo' in str(next(f for f in s if f.name=='Date').type) for _, s in schemas)\n",
    "\n",
    "print('OK_COLS =', ok_cols)\n",
    "print('OK_TZ_SP =', ok_tz)\n",
    "if not ok_cols:\n",
    "    bad = [n for n,s in schemas if s.names != TARGET_COLS]\n",
    "    print('Arquivos com colunas fora do padrão:', bad[:5])\n",
    "if not ok_tz:\n",
    "    bad = []\n",
    "    for n, s in schemas:\n",
    "        f = next((f for f in s if f.name=='Date'), None)\n",
    "        if 'tz=America/Sao_Paulo' not in str(f.type):\n",
    "            bad.append(n)\n",
    "    print('Arquivos com timezone fora do padrão:', bad[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo: petr4_sa_ohlcv_actions_20120101_20250922.parquet\n",
      "Período: 2022-09-01 a 2022-09-30\n",
      "Linhas: 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns, America/Sao_Paulo]",
         "type": "unknown"
        },
        {
         "name": "Open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "High",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Adj Close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "Dividends",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Stock Splits",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2de98e60-8a94-498c-b77f-8c4fd55e01b9",
       "rows": [
        [
         "0",
         "petr4_sa",
         "2022-09-01 00:00:00-03:00",
         "33.36000061035156",
         "33.95000076293945",
         "32.7599983215332",
         "33.849998474121094",
         "18.471288681030273",
         "69184700",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "petr4_sa",
         "2022-09-02 00:00:00-03:00",
         "34.439998626708984",
         "34.56999969482422",
         "33.2599983215332",
         "33.41999816894531",
         "18.23664665222168",
         "81792300",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "petr4_sa",
         "2022-09-05 00:00:00-03:00",
         "33.849998474121094",
         "34.11000061035156",
         "33.150001525878906",
         "33.34000015258789",
         "18.192995071411133",
         "76337600",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "petr4_sa",
         "2022-09-06 00:00:00-03:00",
         "32.27000045776367",
         "32.59000015258789",
         "31.510000228881836",
         "32.099998474121094",
         "17.516345977783203",
         "111813500",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "petr4_sa",
         "2022-09-08 00:00:00-03:00",
         "32.310001373291016",
         "32.779998779296875",
         "31.399999618530273",
         "31.799999237060547",
         "17.352642059326172",
         "63159800",
         "0.0",
         "0.0"
        ],
        [
         "5",
         "petr4_sa",
         "2022-09-09 00:00:00-03:00",
         "32.4900016784668",
         "32.66999816894531",
         "31.700000762939453",
         "31.790000915527344",
         "17.347187042236328",
         "49871900",
         "0.0",
         "0.0"
        ],
        [
         "6",
         "petr4_sa",
         "2022-09-12 00:00:00-03:00",
         "32.150001525878906",
         "32.72999954223633",
         "31.459999084472656",
         "31.479999542236328",
         "17.178028106689453",
         "71374500",
         "0.0",
         "0.0"
        ],
        [
         "7",
         "petr4_sa",
         "2022-09-13 00:00:00-03:00",
         "30.940000534057617",
         "31.440000534057617",
         "30.520000457763672",
         "30.649999618530273",
         "16.725109100341797",
         "88327800",
         "0.0",
         "0.0"
        ],
        [
         "8",
         "petr4_sa",
         "2022-09-14 00:00:00-03:00",
         "30.75",
         "31.43000030517578",
         "30.6299991607666",
         "31.1200008392334",
         "16.98158073425293",
         "49039700",
         "0.0",
         "0.0"
        ],
        [
         "9",
         "petr4_sa",
         "2022-09-15 00:00:00-03:00",
         "30.920000076293945",
         "31.229999542236328",
         "30.799999237060547",
         "31.059999465942383",
         "16.94883918762207",
         "45553200",
         "0.0",
         "0.0"
        ],
        [
         "10",
         "petr4_sa",
         "2022-09-16 00:00:00-03:00",
         "30.860000610351562",
         "30.950000762939453",
         "30.34000015258789",
         "30.780000686645508",
         "16.796049118041992",
         "107303600",
         "0.0",
         "0.0"
        ],
        [
         "11",
         "petr4_sa",
         "2022-09-19 00:00:00-03:00",
         "30.5",
         "31.3799991607666",
         "29.8799991607666",
         "31.270000457763672",
         "17.063432693481445",
         "65559900",
         "0.0",
         "0.0"
        ],
        [
         "12",
         "petr4_sa",
         "2022-09-20 00:00:00-03:00",
         "31.420000076293945",
         "31.600000381469727",
         "30.84000015258789",
         "31.09000015258789",
         "16.9652156829834",
         "67798200",
         "0.0",
         "0.0"
        ],
        [
         "13",
         "petr4_sa",
         "2022-09-21 00:00:00-03:00",
         "31.350000381469727",
         "31.469999313354492",
         "30.889999389648438",
         "31.170000076293945",
         "17.008865356445312",
         "58812200",
         "0.0",
         "0.0"
        ],
        [
         "14",
         "petr4_sa",
         "2022-09-22 00:00:00-03:00",
         "31.479999542236328",
         "32.08000183105469",
         "31.030000686645508",
         "31.940000534057617",
         "17.429040908813477",
         "69764300",
         "0.0",
         "0.0"
        ],
        [
         "15",
         "petr4_sa",
         "2022-09-23 00:00:00-03:00",
         "31.31999969482422",
         "31.389999389648438",
         "29.770000457763672",
         "29.940000534057617",
         "16.337678909301758",
         "138630800",
         "0.0",
         "0.0"
        ],
        [
         "16",
         "petr4_sa",
         "2022-09-26 00:00:00-03:00",
         "29.719999313354492",
         "30.079999923706055",
         "29.270000457763672",
         "29.290000915527344",
         "15.982987403869629",
         "42934600",
         "0.0",
         "0.0"
        ],
        [
         "17",
         "petr4_sa",
         "2022-09-27 00:00:00-03:00",
         "29.65999984741211",
         "29.8799991607666",
         "29.579999923706055",
         "29.670000076293945",
         "16.190343856811523",
         "71087600",
         "0.0",
         "0.0"
        ],
        [
         "18",
         "petr4_sa",
         "2022-09-28 00:00:00-03:00",
         "29.670000076293945",
         "29.81999969482422",
         "28.579999923706055",
         "29.270000457763672",
         "15.972070693969727",
         "104670700",
         "0.0",
         "0.0"
        ],
        [
         "19",
         "petr4_sa",
         "2022-09-29 00:00:00-03:00",
         "28.989999771118164",
         "29.399999618530273",
         "28.600000381469727",
         "29.309999465942383",
         "15.99389934539795",
         "87536500",
         "0.0",
         "0.0"
        ],
        [
         "20",
         "petr4_sa",
         "2022-09-30 00:00:00-03:00",
         "29.219999313354492",
         "30.489999771118164",
         "29.0",
         "29.799999237060547",
         "16.26128387451172",
         "121637100",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 21
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-01 00:00:00-03:00</td>\n",
       "      <td>33.360001</td>\n",
       "      <td>33.950001</td>\n",
       "      <td>32.759998</td>\n",
       "      <td>33.849998</td>\n",
       "      <td>18.471289</td>\n",
       "      <td>69184700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-02 00:00:00-03:00</td>\n",
       "      <td>34.439999</td>\n",
       "      <td>34.570000</td>\n",
       "      <td>33.259998</td>\n",
       "      <td>33.419998</td>\n",
       "      <td>18.236647</td>\n",
       "      <td>81792300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-05 00:00:00-03:00</td>\n",
       "      <td>33.849998</td>\n",
       "      <td>34.110001</td>\n",
       "      <td>33.150002</td>\n",
       "      <td>33.340000</td>\n",
       "      <td>18.192995</td>\n",
       "      <td>76337600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-06 00:00:00-03:00</td>\n",
       "      <td>32.270000</td>\n",
       "      <td>32.590000</td>\n",
       "      <td>31.510000</td>\n",
       "      <td>32.099998</td>\n",
       "      <td>17.516346</td>\n",
       "      <td>111813500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-08 00:00:00-03:00</td>\n",
       "      <td>32.310001</td>\n",
       "      <td>32.779999</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>31.799999</td>\n",
       "      <td>17.352642</td>\n",
       "      <td>63159800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-09 00:00:00-03:00</td>\n",
       "      <td>32.490002</td>\n",
       "      <td>32.669998</td>\n",
       "      <td>31.700001</td>\n",
       "      <td>31.790001</td>\n",
       "      <td>17.347187</td>\n",
       "      <td>49871900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-12 00:00:00-03:00</td>\n",
       "      <td>32.150002</td>\n",
       "      <td>32.730000</td>\n",
       "      <td>31.459999</td>\n",
       "      <td>31.480000</td>\n",
       "      <td>17.178028</td>\n",
       "      <td>71374500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-13 00:00:00-03:00</td>\n",
       "      <td>30.940001</td>\n",
       "      <td>31.440001</td>\n",
       "      <td>30.520000</td>\n",
       "      <td>30.650000</td>\n",
       "      <td>16.725109</td>\n",
       "      <td>88327800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-14 00:00:00-03:00</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>31.430000</td>\n",
       "      <td>30.629999</td>\n",
       "      <td>31.120001</td>\n",
       "      <td>16.981581</td>\n",
       "      <td>49039700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-15 00:00:00-03:00</td>\n",
       "      <td>30.920000</td>\n",
       "      <td>31.230000</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>31.059999</td>\n",
       "      <td>16.948839</td>\n",
       "      <td>45553200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-16 00:00:00-03:00</td>\n",
       "      <td>30.860001</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>30.340000</td>\n",
       "      <td>30.780001</td>\n",
       "      <td>16.796049</td>\n",
       "      <td>107303600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-19 00:00:00-03:00</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>31.379999</td>\n",
       "      <td>29.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>17.063433</td>\n",
       "      <td>65559900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-20 00:00:00-03:00</td>\n",
       "      <td>31.420000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>30.840000</td>\n",
       "      <td>31.090000</td>\n",
       "      <td>16.965216</td>\n",
       "      <td>67798200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-21 00:00:00-03:00</td>\n",
       "      <td>31.350000</td>\n",
       "      <td>31.469999</td>\n",
       "      <td>30.889999</td>\n",
       "      <td>31.170000</td>\n",
       "      <td>17.008865</td>\n",
       "      <td>58812200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-22 00:00:00-03:00</td>\n",
       "      <td>31.480000</td>\n",
       "      <td>32.080002</td>\n",
       "      <td>31.030001</td>\n",
       "      <td>31.940001</td>\n",
       "      <td>17.429041</td>\n",
       "      <td>69764300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-23 00:00:00-03:00</td>\n",
       "      <td>31.320000</td>\n",
       "      <td>31.389999</td>\n",
       "      <td>29.770000</td>\n",
       "      <td>29.940001</td>\n",
       "      <td>16.337679</td>\n",
       "      <td>138630800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-26 00:00:00-03:00</td>\n",
       "      <td>29.719999</td>\n",
       "      <td>30.080000</td>\n",
       "      <td>29.270000</td>\n",
       "      <td>29.290001</td>\n",
       "      <td>15.982987</td>\n",
       "      <td>42934600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-27 00:00:00-03:00</td>\n",
       "      <td>29.660000</td>\n",
       "      <td>29.879999</td>\n",
       "      <td>29.580000</td>\n",
       "      <td>29.670000</td>\n",
       "      <td>16.190344</td>\n",
       "      <td>71087600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-28 00:00:00-03:00</td>\n",
       "      <td>29.670000</td>\n",
       "      <td>29.820000</td>\n",
       "      <td>28.580000</td>\n",
       "      <td>29.270000</td>\n",
       "      <td>15.972071</td>\n",
       "      <td>104670700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-29 00:00:00-03:00</td>\n",
       "      <td>28.990000</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>29.309999</td>\n",
       "      <td>15.993899</td>\n",
       "      <td>87536500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2022-09-30 00:00:00-03:00</td>\n",
       "      <td>29.219999</td>\n",
       "      <td>30.490000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.799999</td>\n",
       "      <td>16.261284</td>\n",
       "      <td>121637100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Symbol                      Date       Open       High        Low  \\\n",
       "0   petr4_sa 2022-09-01 00:00:00-03:00  33.360001  33.950001  32.759998   \n",
       "1   petr4_sa 2022-09-02 00:00:00-03:00  34.439999  34.570000  33.259998   \n",
       "2   petr4_sa 2022-09-05 00:00:00-03:00  33.849998  34.110001  33.150002   \n",
       "3   petr4_sa 2022-09-06 00:00:00-03:00  32.270000  32.590000  31.510000   \n",
       "4   petr4_sa 2022-09-08 00:00:00-03:00  32.310001  32.779999  31.400000   \n",
       "5   petr4_sa 2022-09-09 00:00:00-03:00  32.490002  32.669998  31.700001   \n",
       "6   petr4_sa 2022-09-12 00:00:00-03:00  32.150002  32.730000  31.459999   \n",
       "7   petr4_sa 2022-09-13 00:00:00-03:00  30.940001  31.440001  30.520000   \n",
       "8   petr4_sa 2022-09-14 00:00:00-03:00  30.750000  31.430000  30.629999   \n",
       "9   petr4_sa 2022-09-15 00:00:00-03:00  30.920000  31.230000  30.799999   \n",
       "10  petr4_sa 2022-09-16 00:00:00-03:00  30.860001  30.950001  30.340000   \n",
       "11  petr4_sa 2022-09-19 00:00:00-03:00  30.500000  31.379999  29.879999   \n",
       "12  petr4_sa 2022-09-20 00:00:00-03:00  31.420000  31.600000  30.840000   \n",
       "13  petr4_sa 2022-09-21 00:00:00-03:00  31.350000  31.469999  30.889999   \n",
       "14  petr4_sa 2022-09-22 00:00:00-03:00  31.480000  32.080002  31.030001   \n",
       "15  petr4_sa 2022-09-23 00:00:00-03:00  31.320000  31.389999  29.770000   \n",
       "16  petr4_sa 2022-09-26 00:00:00-03:00  29.719999  30.080000  29.270000   \n",
       "17  petr4_sa 2022-09-27 00:00:00-03:00  29.660000  29.879999  29.580000   \n",
       "18  petr4_sa 2022-09-28 00:00:00-03:00  29.670000  29.820000  28.580000   \n",
       "19  petr4_sa 2022-09-29 00:00:00-03:00  28.990000  29.400000  28.600000   \n",
       "20  petr4_sa 2022-09-30 00:00:00-03:00  29.219999  30.490000  29.000000   \n",
       "\n",
       "        Close  Adj Close     Volume  Dividends  Stock Splits  \n",
       "0   33.849998  18.471289   69184700        0.0           0.0  \n",
       "1   33.419998  18.236647   81792300        0.0           0.0  \n",
       "2   33.340000  18.192995   76337600        0.0           0.0  \n",
       "3   32.099998  17.516346  111813500        0.0           0.0  \n",
       "4   31.799999  17.352642   63159800        0.0           0.0  \n",
       "5   31.790001  17.347187   49871900        0.0           0.0  \n",
       "6   31.480000  17.178028   71374500        0.0           0.0  \n",
       "7   30.650000  16.725109   88327800        0.0           0.0  \n",
       "8   31.120001  16.981581   49039700        0.0           0.0  \n",
       "9   31.059999  16.948839   45553200        0.0           0.0  \n",
       "10  30.780001  16.796049  107303600        0.0           0.0  \n",
       "11  31.270000  17.063433   65559900        0.0           0.0  \n",
       "12  31.090000  16.965216   67798200        0.0           0.0  \n",
       "13  31.170000  17.008865   58812200        0.0           0.0  \n",
       "14  31.940001  17.429041   69764300        0.0           0.0  \n",
       "15  29.940001  16.337679  138630800        0.0           0.0  \n",
       "16  29.290001  15.982987   42934600        0.0           0.0  \n",
       "17  29.670000  16.190344   71087600        0.0           0.0  \n",
       "18  29.270000  15.972071  104670700        0.0           0.0  \n",
       "19  29.309999  15.993899   87536500        0.0           0.0  \n",
       "20  29.799999  16.261284  121637100        0.0           0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar dados de PETR4 em setembro/2022 (camada silver)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Montar caminho para 02_processed usando SHARED_DRIVES se disponível\n",
    "try:\n",
    "    base = Path(SHARED_DRIVES) / 'BOLSA_2026' / 'a_bolsa2026_gemini'\n",
    "    proc_dir = base / '00_data' / '02_processed'\n",
    "    assert proc_dir.exists()\n",
    "except Exception:\n",
    "    proc_dir = Path(r'G:/Drives compartilhados/BOLSA_2026/a_bolsa2026_gemini/00_data/02_processed')\n",
    "\n",
    "# Localizar arquivo silver de PETR4\n",
    "petr4_file = next(proc_dir.glob('petr4_sa_ohlcv_actions_*.parquet'))\n",
    "\n",
    "# Ler dados\n",
    "df = pd.read_parquet(petr4_file)\n",
    "\n",
    "# Garantir Date com tz America/Sao_Paulo (deveria já estar, mas deixamos robusto)\n",
    "if not isinstance(df['Date'].dtype, pd.DatetimeTZDtype):\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.tz_localize('America/Sao_Paulo')\n",
    "\n",
    "# Filtro de setembro de 2022 (intervalo fechado-aberto)\n",
    "start = pd.Timestamp('2022-09-01', tz='America/Sao_Paulo')\n",
    "end = pd.Timestamp('2022-10-01', tz='America/Sao_Paulo')\n",
    "mask = (df['Date'] >= start) & (df['Date'] < end)\n",
    "sep22 = df.loc[mask].sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "print('Arquivo:', petr4_file.name)\n",
    "print('Período:', start.date(), 'a', (end - pd.Timedelta(seconds=1)).date())\n",
    "print('Linhas:', len(sep22))\n",
    "sep22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banco de Dados (Postgres/SQLite) – Camada Silver → SQL\n",
    "\n",
    "Vamos criar um schema SQL para persistir os dados deduplicados e com timezone America/Sao_Paulo, e carregar todos os 31 Parquets da pasta 02_processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_URL = sqlite:///G:/Drives compartilhados/BOLSA_2026/a_bolsa2026_gemini/00_data/03_final/ohlcv.db\n"
     ]
    }
   ],
   "source": [
    "# Configuração de conexão (usa Postgres via env DATABASE_URL; se não setado, cai para SQLite local)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ex.: DATABASE_URL=postgresql+psycopg2://user:pass@host:5432/dbname\n",
    "DB_URL = os.getenv('DATABASE_URL')\n",
    "if not DB_URL:\n",
    "    # fallback local para validação\n",
    "    DB_URL = 'sqlite:///G:/Drives compartilhados/BOLSA_2026/a_bolsa2026_gemini/00_data/03_final/ohlcv.db'\n",
    "    Path('G:/Drives compartilhados/BOLSA_2026/a_bolsa2026_gemini/00_data/03_final').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('DB_URL =', DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela ohlcv_daily pronta.\n"
     ]
    }
   ],
   "source": [
    "# Criar engine SQLAlchemy e schema da tabela\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import text\n",
    "\n",
    "engine = sa.create_engine(DB_URL, future=True)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # Postgres: timestamptz; SQLite: armazena texto ISO8601 com tz ou timestamp naive (vamos manter texto ISO para portabilidade)\n",
    "    # Chave primária: (symbol, date)\n",
    "    conn.execute(text(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS ohlcv_daily (\n",
    "        symbol TEXT NOT NULL,\n",
    "        date   TEXT NOT NULL,\n",
    "        open   DOUBLE PRECISION,\n",
    "        high   DOUBLE PRECISION,\n",
    "        low    DOUBLE PRECISION,\n",
    "        close  DOUBLE PRECISION,\n",
    "        adj_close DOUBLE PRECISION,\n",
    "        volume BIGINT,\n",
    "        dividends DOUBLE PRECISION,\n",
    "        stock_splits DOUBLE PRECISION,\n",
    "        PRIMARY KEY (symbol, date)\n",
    "    )\n",
    "    \"\"\"))\n",
    "\n",
    "print('Tabela ohlcv_daily pronta.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos a carregar: 31\n",
      "_bvsp_ohlcv_actions_20120101_20250922.parquet: upsert 3400 linhas\n",
      "_gspc_ohlcv_actions_20120101_20250922.parquet: upsert 3449 linhas\n",
      "_tnx_ohlcv_actions_20120101_20250922.parquet: upsert 3448 linhas\n",
      "_vix_ohlcv_actions_20120101_20250922.parquet: upsert 3449 linhas\n",
      "abev3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "b3sa3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "bbas3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "bz=f_ohlcv_actions_20120101_20250922.parquet: upsert 3432 linhas\n",
      "cple6_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3408 linhas\n",
      "csna3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "dx-y.nyb_ohlcv_actions_20120101_20250922.parquet: upsert 3450 linhas\n",
      "elet3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "ewz_ohlcv_actions_20120101_20250922.parquet: upsert 3449 linhas\n",
      "ggbr4_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "hapv3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 1840 linhas\n",
      "itub4_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "lren3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "petr4_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "prio3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "pssa3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "rail3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 2606 linhas\n",
      "rdor3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 1187 linhas\n",
      "sbsp3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "suzb3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "taee11_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "tims3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "tots3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "ugpa3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "vale3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "vivt3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "wege3_sa_ohlcv_actions_20120101_20250922.parquet: upsert 3409 linhas\n",
      "Total de linhas upsertadas: 101298\n"
     ]
    }
   ],
   "source": [
    "# Carregar todos os Parquets de 02_processed para o banco (upsert deduplicado)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import text\n",
    "\n",
    "SILVER_DIR = Path('G:/Drives compartilhados/BOLSA_2026/a_bolsa2026_gemini/00_data/02_processed')\n",
    "files = sorted(SILVER_DIR.glob('*.parquet'))\n",
    "print('Arquivos a carregar:', len(files))\n",
    "\n",
    "dialect = sa.create_engine(DB_URL).dialect.name\n",
    "is_pg = (dialect == 'postgresql')\n",
    "\n",
    "# Preparar comandos de upsert específicos por SGBD\n",
    "if is_pg:\n",
    "    upsert_sql = text(\"\"\"\n",
    "        INSERT INTO ohlcv_daily (symbol, date, open, high, low, close, adj_close, volume, dividends, stock_splits)\n",
    "        VALUES (:symbol, :date, :open, :high, :low, :close, :adj_close, :volume, :dividends, :stock_splits)\n",
    "        ON CONFLICT (symbol, date) DO UPDATE SET\n",
    "            open=EXCLUDED.open,\n",
    "            high=EXCLUDED.high,\n",
    "            low=EXCLUDED.low,\n",
    "            close=EXCLUDED.close,\n",
    "            adj_close=EXCLUDED.adj_close,\n",
    "            volume=EXCLUDED.volume,\n",
    "            dividends=EXCLUDED.dividends,\n",
    "            stock_splits=EXCLUDED.stock_splits\n",
    "    \"\"\")\n",
    "else:\n",
    "    # SQLite\n",
    "    upsert_sql = text(\"\"\"\n",
    "        INSERT OR REPLACE INTO ohlcv_daily (symbol, date, open, high, low, close, adj_close, volume, dividends, stock_splits)\n",
    "        VALUES (:symbol, :date, :open, :high, :low, :close, :adj_close, :volume, :dividends, :stock_splits)\n",
    "    \"\"\")\n",
    "\n",
    "engine = sa.create_engine(DB_URL, future=True)\n",
    "\n",
    "def to_rows(df: pd.DataFrame):\n",
    "    # Garantir colunas e tipos\n",
    "    cols = ['Symbol','Date','Open','High','Low','Close','Adj Close','Volume','Dividends','Stock Splits']\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    # Timezone: persistir ISO 8601 com offset (-03:00) mantendo America/Sao_Paulo\n",
    "    dt = df['Date']\n",
    "    if not isinstance(dt.dtype, pd.DatetimeTZDtype):\n",
    "        dt = pd.to_datetime(dt, errors='coerce').dt.tz_localize('America/Sao_Paulo')\n",
    "    else:\n",
    "        dt = dt.dt.tz_convert('America/Sao_Paulo')\n",
    "    date_iso = dt.apply(lambda x: x.isoformat() if pd.notnull(x) else None)\n",
    "\n",
    "    # Deduplicar por (Symbol, Date)\n",
    "    tmp = df.copy()\n",
    "    tmp['__date_iso__'] = date_iso\n",
    "    tmp = tmp.dropna(subset=['__date_iso__'])\n",
    "    tmp = tmp.sort_values(['Symbol','__date_iso__']).drop_duplicates(['Symbol','__date_iso__'], keep='last')\n",
    "\n",
    "    # Construir DataFrame final com nomes de colunas do SQL\n",
    "    out = pd.DataFrame({\n",
    "        'symbol': tmp['Symbol'].astype(str).str.lower(),\n",
    "        'date': tmp['__date_iso__'],\n",
    "        'open': pd.to_numeric(tmp['Open'], errors='coerce'),\n",
    "        'high': pd.to_numeric(tmp['High'], errors='coerce'),\n",
    "        'low': pd.to_numeric(tmp['Low'], errors='coerce'),\n",
    "        'close': pd.to_numeric(tmp['Close'], errors='coerce'),\n",
    "        'adj_close': pd.to_numeric(tmp['Adj Close'], errors='coerce'),\n",
    "        'volume': pd.to_numeric(tmp['Volume'], errors='coerce').astype('Int64'),\n",
    "        'dividends': pd.to_numeric(tmp['Dividends'], errors='coerce'),\n",
    "        'stock_splits': pd.to_numeric(tmp['Stock Splits'], errors='coerce'),\n",
    "    })\n",
    "\n",
    "    # Converter NaN/<NA> para None (para bind SQL)\n",
    "    out = out.astype(object).where(pd.notnull(out), None)\n",
    "    return out.to_dict(orient='records')\n",
    "\n",
    "loaded = 0\n",
    "with engine.begin() as conn:\n",
    "    for p in files:\n",
    "        df = pd.read_parquet(p)\n",
    "        # Assegurar presença da coluna Symbol no silver\n",
    "        if 'Symbol' not in df.columns:\n",
    "            # Inferir do nome, fallback\n",
    "            sym = p.name.split('_ohlcv_actions_')[0].lstrip('_').lower()\n",
    "            df.insert(0, 'Symbol', sym)\n",
    "        rows = to_rows(df)\n",
    "        if rows:\n",
    "            conn.execute(upsert_sql, rows)\n",
    "            loaded += len(rows)\n",
    "        print(f\"{p.name}: upsert {len(rows)} linhas\")\n",
    "\n",
    "print('Total de linhas upsertadas:', loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total linhas: 101298\n",
      "('abev3_sa', '2012-01-02T00:00:00-02:00', '2025-09-19T00:00:00-03:00', 3409)\n",
      "('b3sa3_sa', '2012-01-02T00:00:00-02:00', '2025-09-19T00:00:00-03:00', 3409)\n",
      "('bbas3_sa', '2012-01-02T00:00:00-02:00', '2025-09-19T00:00:00-03:00', 3409)\n",
      "('bvsp', '2012-01-03T00:00:00-02:00', '2025-09-19T00:00:00-03:00', 3400)\n",
      "('bz=f', '2012-01-03T03:00:00-02:00', '2025-09-19T01:00:00-03:00', 3432)\n",
      "('cple6_sa', '2012-01-02T00:00:00-02:00', '2025-09-19T00:00:00-03:00', 3408)\n",
      "('csna3_sa', '2012-01-02T00:00:00-02:00', '2025-09-19T00:00:00-03:00', 3409)\n",
      "('dx-y.nyb', '2012-01-03T03:00:00-02:00', '2025-09-19T01:00:00-03:00', 3450)\n",
      "('elet3_sa', '2012-01-02T00:00:00-02:00', '2025-09-19T00:00:00-03:00', 3409)\n",
      "('ewz', '2012-01-03T03:00:00-02:00', '2025-09-19T01:00:00-03:00', 3449)\n"
     ]
    }
   ],
   "source": [
    "# Verificações rápidas no banco: contagem total e amostra por símbolo\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import text\n",
    "\n",
    "engine = sa.create_engine(DB_URL, future=True)\n",
    "with engine.begin() as conn:\n",
    "    total = conn.execute(text('SELECT COUNT(*) FROM ohlcv_daily')).scalar_one()\n",
    "    print('Total linhas:', total)\n",
    "    rows = conn.execute(text('SELECT symbol, MIN(date), MAX(date), COUNT(*) FROM ohlcv_daily GROUP BY symbol ORDER BY symbol LIMIT 10')).fetchall()\n",
    "    for r in rows:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atualização diária e persistencia do Postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotina diária — Delta de datas a buscar\n",
    "\n",
    "> Objetivo deste bloco: descobrir, para cada símbolo, o intervalo de datas que falta entre a última data persistida no banco (`ohlcv_daily`) e a última data disponível via fonte externa (Yahoo Finance), sem ainda realizar a ingestão. O resultado é um relatório CSV em `04_outputs/reports/` com janelas de busca por símbolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_URL = sqlite:///G:\\Drives compartilhados\\BOLSA_2026\\a_bolsa2026_gemini\\00_data\\03_final\\ohlcv.db\n"
     ]
    }
   ],
   "source": [
    "# Imports e setup de paths/engine para rotina diária (delta de datas)\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import text\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# Pastas\n",
    "ROOT = Path(r\"G:/Drives compartilhados/BOLSA_2026/a_bolsa2026_gemini\")\n",
    "RAW_DIR = ROOT / '00_data' / '01_raw'\n",
    "REPORTS_DIR = ROOT / '04_outputs' / 'reports'\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Banco (usa DATABASE_URL se existir; senão, SQLite local)\n",
    "DB_URL = os.getenv('DATABASE_URL') or f\"sqlite:///{ROOT / '00_data' / '03_final' / 'ohlcv.db'}\"\n",
    "engine = sa.create_engine(DB_URL, future=True)\n",
    "print('DB_URL =', DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração Twelve Data (API)\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "\n",
    "TD_API_KEY = os.getenv('TWELVE_DATA_API_KEY') or 'd636f3fa4f2042a9ac3bf9ead03d2dc0'\n",
    "TD_BASE_URL = 'https://api.twelvedata.com'\n",
    "TD_DEFAULT_TZ = 'America/Sao_Paulo'\n",
    "TD_SESSION = requests.Session()\n",
    "# Intervalo entre chamadas para aliviar rate-limit (ajuste se necessário)\n",
    "TD_SLEEP_SECONDS = float(os.getenv('TWELVE_DATA_SLEEP', '0.2'))\n",
    "\n",
    "print('TD_BASE_URL =', TD_BASE_URL)\n",
    "print('TD_DEFAULT_TZ =', TD_DEFAULT_TZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de 31 símbolos a monitorar (derivada do manifesto raw + índices/macros)\n",
    "SYMBOLS = [\n",
    "    'itub4_sa','bbas3_sa','b3sa3_sa','pssa3_sa','vale3_sa','ggbr4_sa','csna3_sa','suzb3_sa',\n",
    "    'petr4_sa','prio3_sa','ugpa3_sa','elet3_sa','taee11_sa','cple6_sa','sbsp3_sa','vivt3_sa',\n",
    "    'tims3_sa','rdor3_sa','hapv3_sa','abev3_sa','wege3_sa','tots3_sa','lren3_sa','rail3_sa',\n",
    "    '_bvsp','ewz','_gspc','_vix','dx-y.nyb','_tnx','bz=f'\n",
    " ]\n",
    "\n",
    "# Mapa para Twelve Data\n",
    "# Regras:\n",
    "# - Ações B3: TICKER.SA (ex.: PETR4.SA)\n",
    "# - ETFs/índices/forex/commodities seguem convenção Twelve Data\n",
    "TD_MAP = {\n",
    "    'itub4_sa': 'ITUB4.SA','bbas3_sa': 'BBAS3.SA','b3sa3_sa': 'B3SA3.SA','pssa3_sa': 'PSSA3.SA','vale3_sa': 'VALE3.SA',\n",
    "    'ggbr4_sa': 'GGBR4.SA','csna3_sa': 'CSNA3.SA','suzb3_sa': 'SUZB3.SA','petr4_sa': 'PETR4.SA','prio3_sa': 'PRIO3.SA',\n",
    "    'ugpa3_sa': 'UGPA3.SA','elet3_sa': 'ELET3.SA','taee11_sa': 'TAEE11.SA','cple6_sa': 'CPLE6.SA','sbsp3_sa': 'SBSP3.SA',\n",
    "    'vivt3_sa': 'VIVT3.SA','tims3_sa': 'TIMS3.SA','rdor3_sa': 'RDOR3.SA','hapv3_sa': 'HAPV3.SA','abev3_sa': 'ABEV3.SA',\n",
    "    'wege3_sa': 'WEGE3.SA','tots3_sa': 'TOTS3.SA','lren3_sa': 'LREN3.SA','rail3_sa': 'RAIL3.SA',\n",
    "    # Índices/ETFs/Macros (verificamos convenções comuns do Twelve Data):\n",
    "    '_bvsp': 'BVSP',        # Ibovespa index\n",
    "    'ewz': 'EWZ',           # iShares MSCI Brazil ETF (NYSE)\n",
    "    '_gspc': 'SPX',         # S&P 500 index ticker common alias in TD\n",
    "    '_vix': 'VIX',          # CBOE Volatility Index\n",
    "    'dx-y.nyb': 'DXY',      # US Dollar Index\n",
    "    '_tnx': 'TNX',          # 10-Year Treasury Note Yield Index\n",
    "    'bz=f': 'BZ=F'          # Brent (check TD support; if unsupported, fallback via alt symbol)\n",
    "}\n",
    "len(SYMBOLS), len(TD_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções auxiliares: última data no DB e via Twelve Data\n",
    "import contextlib\n",
    "import pandas as pd\n",
    "\n",
    "def to_db_symbol(sym: str) -> str:\n",
    "    \"\"\"Normaliza o símbolo para o padrão persistido no DB.\n",
    "    Regra aplicada no carregamento Silver->DB: lowercase e remoção de underscores à esquerda.\n",
    "    Ex.: \"_bvsp\" -> \"bvsp\", \"itub4_sa\" -> \"itub4_sa\".\n",
    "    \"\"\"\n",
    "    return sym.lstrip('_').lower() if isinstance(sym, str) else sym\n",
    "\n",
    "def get_last_persisted_date(engine, symbol: str) -> pd.Timestamp | None:\n",
    "    \"\"\"Retorna a última data (tz-aware) para o símbolo no banco (ohlcv_daily).\n",
    "    Considera que a coluna 'date' é ISO 8601 com offset; converte para tz America/Sao_Paulo.\n",
    "    Usa o símbolo normalizado para o padrão do DB (ex.: _bvsp -> bvsp).\n",
    "    \"\"\"\n",
    "    from sqlalchemy import text\n",
    "    symbol_db = to_db_symbol(symbol)\n",
    "    q = text(\"SELECT MAX(date) FROM ohlcv_daily WHERE symbol = :s\")\n",
    "    with engine.begin() as conn:\n",
    "        val = conn.execute(q, {'s': symbol_db}).scalar()\n",
    "    if not val:\n",
    "        return None\n",
    "    # Converte string ISO para Timestamp tz-aware\n",
    "    try:\n",
    "        ts = pd.to_datetime(val)\n",
    "        if ts.tz is None:\n",
    "            ts = ts.tz_localize('America/Sao_Paulo')\n",
    "        else:\n",
    "            ts = ts.tz_convert('America/Sao_Paulo')\n",
    "        return ts\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Twelve Data helpers\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "def td_request(endpoint: str, params: dict) -> dict | None:\n",
    "    url = f\"{TD_BASE_URL.rstrip('/')}/{endpoint.lstrip('/')}\"\n",
    "    p = {**params, 'apikey': TD_API_KEY}\n",
    "    try:\n",
    "        r = TD_SESSION.get(url, params=p, timeout=30)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        data = r.json()\n",
    "        # Twelve Data error payload has 'status':'error'\n",
    "        if isinstance(data, dict) and data.get('status') == 'error':\n",
    "            return None\n",
    "        return data\n",
    "    except Exception:\n",
    "        return None\n",
    "    finally:\n",
    "        # respeitar pequeno intervalo entre chamadas\n",
    "        time.sleep(TD_SLEEP_SECONDS)\n",
    "\n",
    "def get_last_available_date_td(td_symbol: str) -> pd.Timestamp | None:\n",
    "    \"\"\"Obtém a última data diária disponível via Twelve Data para o símbolo informado.\"\"\"\n",
    "    data = td_request('time_series', {\n",
    "        'symbol': td_symbol,\n",
    "        'interval': '1day',\n",
    "        'outputsize': 1,\n",
    "        'order': 'desc',\n",
    "        'timezone': TD_DEFAULT_TZ,\n",
    "        'format': 'JSON',\n",
    "    })\n",
    "    if not data or 'values' not in data or not data['values']:\n",
    "        return None\n",
    "    # 'datetime' costuma vir como 'YYYY-MM-DD' (sem hora)\n",
    "    dt_str = data['values'][0].get('datetime')\n",
    "    if not dt_str:\n",
    "        return None\n",
    "    try:\n",
    "        d = pd.to_datetime(dt_str).date()\n",
    "        return pd.Timestamp(d, tz=TD_DEFAULT_TZ)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def td_download_range(td_symbol: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"Baixa candles diários [start_date, end_date] inclusive via Twelve Data e retorna DataFrame padronizado.\n",
    "    start_date/end_date: 'YYYY-MM-DD'.\n",
    "    \"\"\"\n",
    "    data = td_request('time_series', {\n",
    "        'symbol': td_symbol,\n",
    "        'interval': '1day',\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'order': 'asc',\n",
    "        'timezone': TD_DEFAULT_TZ,\n",
    "        'format': 'JSON',\n",
    "    })\n",
    "    if not data or 'values' not in data or not isinstance(data['values'], list) or not data['values']:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    vals = data['values']\n",
    "    df = pd.DataFrame(vals)\n",
    "    # Normalizar nomes\n",
    "    rename_map = {\n",
    "        'datetime': 'Date',\n",
    "        'open': 'Open',\n",
    "        'high': 'High',\n",
    "        'low': 'Low',\n",
    "        'close': 'Close',\n",
    "        'volume': 'Volume',\n",
    "    }\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    # Tipos numéricos\n",
    "    for c in ['Open','High','Low','Close','Volume']:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        else:\n",
    "            df[c] = pd.NA\n",
    "\n",
    "    # Adj Close = Close (sem ajuste corporativo diário via TD aqui). Dividends/Splits ausentes nesta chamada\n",
    "    df['Adj Close'] = df['Close']\n",
    "    df['Dividends'] = pd.NA\n",
    "    df['Stock Splits'] = pd.NA\n",
    "\n",
    "    # Date como tz America/Sao_Paulo (Twelve Data já devolve no tz pedido, mas sem offset)\n",
    "    dt = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    # As strings costumam ser 'YYYY-MM-DD' => timezone-naive; localizamos para SP\n",
    "    df['Date'] = dt.dt.tz_localize(TD_DEFAULT_TZ, nonexistent='shift_forward', ambiguous='NaT')\n",
    "\n",
    "    # Ordenar por data e remover duplicatas\n",
    "    df = df.sort_values('Date').drop_duplicates('Date', keep='last')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff (ontem SP): 2025-09-30\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TD_MAP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sym \u001b[38;5;129;01min\u001b[39;00m SYMBOLS:\n\u001b[1;32m---> 13\u001b[0m     td_symbol \u001b[38;5;241m=\u001b[39m \u001b[43mTD_MAP\u001b[49m\u001b[38;5;241m.\u001b[39mget(sym)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m td_symbol:\n\u001b[0;32m     15\u001b[0m         rows\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m: sym, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol_db\u001b[39m\u001b[38;5;124m'\u001b[39m: to_db_symbol(sym), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myf_ticker\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_db_date\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_yf_date\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfetch_from\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfetch_to\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdays_missing\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno-mapping\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TD_MAP' is not defined"
     ]
    }
   ],
   "source": [
    "# Calcular janelas de delta (por símbolo) sem ingerir (capando no \"ontem SP\"):\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Data de corte: ontem no fuso America/Sao_Paulo\n",
    "sp_now = pd.Timestamp.now(tz='America/Sao_Paulo')\n",
    "cutoff_date = (sp_now - pd.Timedelta(days=1)).date()\n",
    "cutoff_ts = pd.Timestamp(cutoff_date, tz='America/Sao_Paulo')\n",
    "print('Cutoff (ontem SP):', cutoff_date)\n",
    "\n",
    "rows = []\n",
    "for sym in SYMBOLS:\n",
    "    td_symbol = TD_MAP.get(sym)\n",
    "    if not td_symbol:\n",
    "        rows.append({'symbol': sym, 'symbol_db': to_db_symbol(sym), 'yf_ticker': None, 'last_db_date': None, 'last_yf_date': None, 'fetch_from': None, 'fetch_to': None, 'days_missing': None, 'status': 'no-mapping'})\n",
    "        continue\n",
    "\n",
    "    last_db = get_last_persisted_date(engine, sym)\n",
    "    last_yf = get_last_available_date_td(td_symbol)\n",
    "\n",
    "    if last_yf is None:\n",
    "        rows.append({'symbol': sym, 'symbol_db': to_db_symbol(sym), 'yf_ticker': td_symbol, 'last_db_date': last_db, 'last_yf_date': None, 'fetch_from': None, 'fetch_to': None, 'days_missing': None, 'status': 'no-yf-data'})\n",
    "        continue\n",
    "\n",
    "    # Aplicar corte: não permitir buscar além de cutoff_ts (ontem SP)\n",
    "    effective_to = min(last_yf, cutoff_ts)\n",
    "\n",
    "    # Regra de janela\n",
    "    if last_db is None:\n",
    "        fetch_from = pd.Timestamp('2012-01-01', tz='America/Sao_Paulo')\n",
    "    else:\n",
    "        fetch_from = pd.Timestamp(last_db.date() + timedelta(days=1), tz='America/Sao_Paulo')\n",
    "\n",
    "    fetch_to = effective_to\n",
    "    if fetch_from.date() > fetch_to.date():\n",
    "        days_missing = 0\n",
    "        status = 'up-to-date'\n",
    "        fetch_from_out = None\n",
    "        fetch_to_out = None\n",
    "    else:\n",
    "        days_missing = (fetch_to.date() - fetch_from.date()).days + 1\n",
    "        status = 'delta' if days_missing > 0 else 'up-to-date'\n",
    "        fetch_from_out = fetch_from\n",
    "        fetch_to_out = fetch_to\n",
    "\n",
    "    rows.append({\n",
    "        'symbol': sym,\n",
    "        'symbol_db': to_db_symbol(sym),\n",
    "        'yf_ticker': td_symbol,\n",
    "        'last_db_date': last_db,\n",
    "        'last_yf_date': last_yf,\n",
    "        'fetch_from': fetch_from_out,\n",
    "        'fetch_to': fetch_to_out,\n",
    "        'days_missing': days_missing,\n",
    "        'status': status,\n",
    "    })\n",
    "\n",
    "delta_df = pd.DataFrame(rows)\n",
    "# Ordenar com prioridade para quem tem delta\n",
    "delta_df = delta_df.sort_values(['status','symbol'], ascending=[True, True]).reset_index(drop=True)\n",
    "print('Símbolos no mapeamento:', len(SYMBOLS))\n",
    "print('Com delta > 0 dias:', int((delta_df['days_missing'].fillna(0) > 0).sum()))\n",
    "delta_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório salvo em: G:\\Drives compartilhados\\BOLSA_2026\\a_bolsa2026_gemini\\04_outputs\\reports\\delta_ranges_20251001_083245.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "symbol_db",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "yf_ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "last_db_date",
         "rawType": "datetime64[ns, America/Sao_Paulo]",
         "type": "unknown"
        },
        {
         "name": "last_yf_date",
         "rawType": "datetime64[ns, America/Sao_Paulo]",
         "type": "unknown"
        },
        {
         "name": "fetch_from",
         "rawType": "datetime64[ns, America/Sao_Paulo]",
         "type": "unknown"
        },
        {
         "name": "fetch_to",
         "rawType": "datetime64[ns, America/Sao_Paulo]",
         "type": "unknown"
        },
        {
         "name": "days_missing",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "status",
         "rawType": "category",
         "type": "unknown"
        }
       ],
       "ref": "894c6a3a-39ff-4530-8155-fdba6a11213a",
       "rows": [
        [
         "0",
         "abev3_sa",
         "abev3_sa",
         "ABEV3.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "1",
         "cple6_sa",
         "cple6_sa",
         "CPLE6.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "2",
         "csna3_sa",
         "csna3_sa",
         "CSNA3.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "3",
         "elet3_sa",
         "elet3_sa",
         "ELET3.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "4",
         "ggbr4_sa",
         "ggbr4_sa",
         "GGBR4.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "5",
         "hapv3_sa",
         "hapv3_sa",
         "HAPV3.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "6",
         "rail3_sa",
         "rail3_sa",
         "RAIL3.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "7",
         "rdor3_sa",
         "rdor3_sa",
         "RDOR3.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "8",
         "suzb3_sa",
         "suzb3_sa",
         "SUZB3.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "9",
         "taee11_sa",
         "taee11_sa",
         "TAEE11.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "10",
         "ugpa3_sa",
         "ugpa3_sa",
         "UGPA3.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "11",
         "vale3_sa",
         "vale3_sa",
         "VALE3.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "12",
         "vivt3_sa",
         "vivt3_sa",
         "VIVT3.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "13",
         "wege3_sa",
         "wege3_sa",
         "WEGE3.SA",
         "2025-09-26 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "2025-09-27 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         "3",
         "delta"
        ],
        [
         "14",
         "_bvsp",
         "bvsp",
         "^BVSP",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "15",
         "_gspc",
         "gspc",
         "^GSPC",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "16",
         "_tnx",
         "tnx",
         "^TNX",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "17",
         "_vix",
         "vix",
         "^VIX",
         "2025-09-30 00:00:00-03:00",
         "2025-09-30 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "18",
         "b3sa3_sa",
         "b3sa3_sa",
         "B3SA3.SA",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "19",
         "bbas3_sa",
         "bbas3_sa",
         "BBAS3.SA",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "20",
         "bz=f",
         "bz=f",
         "BZ=F",
         "2025-09-30 00:00:00-03:00",
         "2025-09-30 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "21",
         "dx-y.nyb",
         "dx-y.nyb",
         "DX-Y.NYB",
         "2025-09-30 00:00:00-03:00",
         "2025-09-30 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "22",
         "ewz",
         "ewz",
         "EWZ",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "23",
         "itub4_sa",
         "itub4_sa",
         "ITUB4.SA",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "24",
         "lren3_sa",
         "lren3_sa",
         "LREN3.SA",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "25",
         "petr4_sa",
         "petr4_sa",
         "PETR4.SA",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "26",
         "prio3_sa",
         "prio3_sa",
         "PRIO3.SA",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "27",
         "pssa3_sa",
         "pssa3_sa",
         "PSSA3.SA",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "28",
         "sbsp3_sa",
         "sbsp3_sa",
         "SBSP3.SA",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ],
        [
         "29",
         "tims3_sa",
         "tims3_sa",
         "TIMS3.SA",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29 00:00:00-03:00",
         null,
         null,
         "0",
         "up-to-date"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 30
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>symbol_db</th>\n",
       "      <th>yf_ticker</th>\n",
       "      <th>last_db_date</th>\n",
       "      <th>last_yf_date</th>\n",
       "      <th>fetch_from</th>\n",
       "      <th>fetch_to</th>\n",
       "      <th>days_missing</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abev3_sa</td>\n",
       "      <td>abev3_sa</td>\n",
       "      <td>ABEV3.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cple6_sa</td>\n",
       "      <td>cple6_sa</td>\n",
       "      <td>CPLE6.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>csna3_sa</td>\n",
       "      <td>csna3_sa</td>\n",
       "      <td>CSNA3.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elet3_sa</td>\n",
       "      <td>elet3_sa</td>\n",
       "      <td>ELET3.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ggbr4_sa</td>\n",
       "      <td>ggbr4_sa</td>\n",
       "      <td>GGBR4.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hapv3_sa</td>\n",
       "      <td>hapv3_sa</td>\n",
       "      <td>HAPV3.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rail3_sa</td>\n",
       "      <td>rail3_sa</td>\n",
       "      <td>RAIL3.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rdor3_sa</td>\n",
       "      <td>rdor3_sa</td>\n",
       "      <td>RDOR3.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>suzb3_sa</td>\n",
       "      <td>suzb3_sa</td>\n",
       "      <td>SUZB3.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>taee11_sa</td>\n",
       "      <td>taee11_sa</td>\n",
       "      <td>TAEE11.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ugpa3_sa</td>\n",
       "      <td>ugpa3_sa</td>\n",
       "      <td>UGPA3.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vale3_sa</td>\n",
       "      <td>vale3_sa</td>\n",
       "      <td>VALE3.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vivt3_sa</td>\n",
       "      <td>vivt3_sa</td>\n",
       "      <td>VIVT3.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wege3_sa</td>\n",
       "      <td>wege3_sa</td>\n",
       "      <td>WEGE3.SA</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-27 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>_bvsp</td>\n",
       "      <td>bvsp</td>\n",
       "      <td>^BVSP</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>_gspc</td>\n",
       "      <td>gspc</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>_tnx</td>\n",
       "      <td>tnx</td>\n",
       "      <td>^TNX</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>_vix</td>\n",
       "      <td>vix</td>\n",
       "      <td>^VIX</td>\n",
       "      <td>2025-09-30 00:00:00-03:00</td>\n",
       "      <td>2025-09-30 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>b3sa3_sa</td>\n",
       "      <td>b3sa3_sa</td>\n",
       "      <td>B3SA3.SA</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bbas3_sa</td>\n",
       "      <td>bbas3_sa</td>\n",
       "      <td>BBAS3.SA</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bz=f</td>\n",
       "      <td>bz=f</td>\n",
       "      <td>BZ=F</td>\n",
       "      <td>2025-09-30 00:00:00-03:00</td>\n",
       "      <td>2025-09-30 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dx-y.nyb</td>\n",
       "      <td>dx-y.nyb</td>\n",
       "      <td>DX-Y.NYB</td>\n",
       "      <td>2025-09-30 00:00:00-03:00</td>\n",
       "      <td>2025-09-30 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ewz</td>\n",
       "      <td>ewz</td>\n",
       "      <td>EWZ</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>itub4_sa</td>\n",
       "      <td>itub4_sa</td>\n",
       "      <td>ITUB4.SA</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lren3_sa</td>\n",
       "      <td>lren3_sa</td>\n",
       "      <td>LREN3.SA</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>PETR4.SA</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>prio3_sa</td>\n",
       "      <td>prio3_sa</td>\n",
       "      <td>PRIO3.SA</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pssa3_sa</td>\n",
       "      <td>pssa3_sa</td>\n",
       "      <td>PSSA3.SA</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sbsp3_sa</td>\n",
       "      <td>sbsp3_sa</td>\n",
       "      <td>SBSP3.SA</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tims3_sa</td>\n",
       "      <td>tims3_sa</td>\n",
       "      <td>TIMS3.SA</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>up-to-date</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       symbol  symbol_db  yf_ticker              last_db_date  \\\n",
       "0    abev3_sa   abev3_sa   ABEV3.SA 2025-09-26 00:00:00-03:00   \n",
       "1    cple6_sa   cple6_sa   CPLE6.SA 2025-09-26 00:00:00-03:00   \n",
       "2    csna3_sa   csna3_sa   CSNA3.SA 2025-09-26 00:00:00-03:00   \n",
       "3    elet3_sa   elet3_sa   ELET3.SA 2025-09-26 00:00:00-03:00   \n",
       "4    ggbr4_sa   ggbr4_sa   GGBR4.SA 2025-09-26 00:00:00-03:00   \n",
       "5    hapv3_sa   hapv3_sa   HAPV3.SA 2025-09-26 00:00:00-03:00   \n",
       "6    rail3_sa   rail3_sa   RAIL3.SA 2025-09-26 00:00:00-03:00   \n",
       "7    rdor3_sa   rdor3_sa   RDOR3.SA 2025-09-26 00:00:00-03:00   \n",
       "8    suzb3_sa   suzb3_sa   SUZB3.SA 2025-09-26 00:00:00-03:00   \n",
       "9   taee11_sa  taee11_sa  TAEE11.SA 2025-09-26 00:00:00-03:00   \n",
       "10   ugpa3_sa   ugpa3_sa   UGPA3.SA 2025-09-26 00:00:00-03:00   \n",
       "11   vale3_sa   vale3_sa   VALE3.SA 2025-09-26 00:00:00-03:00   \n",
       "12   vivt3_sa   vivt3_sa   VIVT3.SA 2025-09-26 00:00:00-03:00   \n",
       "13   wege3_sa   wege3_sa   WEGE3.SA 2025-09-26 00:00:00-03:00   \n",
       "14      _bvsp       bvsp      ^BVSP 2025-09-29 00:00:00-03:00   \n",
       "15      _gspc       gspc      ^GSPC 2025-09-29 00:00:00-03:00   \n",
       "16       _tnx        tnx       ^TNX 2025-09-29 00:00:00-03:00   \n",
       "17       _vix        vix       ^VIX 2025-09-30 00:00:00-03:00   \n",
       "18   b3sa3_sa   b3sa3_sa   B3SA3.SA 2025-09-29 00:00:00-03:00   \n",
       "19   bbas3_sa   bbas3_sa   BBAS3.SA 2025-09-29 00:00:00-03:00   \n",
       "20       bz=f       bz=f       BZ=F 2025-09-30 00:00:00-03:00   \n",
       "21   dx-y.nyb   dx-y.nyb   DX-Y.NYB 2025-09-30 00:00:00-03:00   \n",
       "22        ewz        ewz        EWZ 2025-09-29 00:00:00-03:00   \n",
       "23   itub4_sa   itub4_sa   ITUB4.SA 2025-09-29 00:00:00-03:00   \n",
       "24   lren3_sa   lren3_sa   LREN3.SA 2025-09-29 00:00:00-03:00   \n",
       "25   petr4_sa   petr4_sa   PETR4.SA 2025-09-29 00:00:00-03:00   \n",
       "26   prio3_sa   prio3_sa   PRIO3.SA 2025-09-29 00:00:00-03:00   \n",
       "27   pssa3_sa   pssa3_sa   PSSA3.SA 2025-09-29 00:00:00-03:00   \n",
       "28   sbsp3_sa   sbsp3_sa   SBSP3.SA 2025-09-29 00:00:00-03:00   \n",
       "29   tims3_sa   tims3_sa   TIMS3.SA 2025-09-29 00:00:00-03:00   \n",
       "\n",
       "                last_yf_date                fetch_from  \\\n",
       "0  2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "1  2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "2  2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "3  2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "4  2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "5  2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "6  2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "7  2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "8  2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "9  2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "10 2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "11 2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "12 2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "13 2025-09-29 00:00:00-03:00 2025-09-27 00:00:00-03:00   \n",
       "14 2025-09-29 00:00:00-03:00                       NaT   \n",
       "15 2025-09-29 00:00:00-03:00                       NaT   \n",
       "16 2025-09-29 00:00:00-03:00                       NaT   \n",
       "17 2025-09-30 00:00:00-03:00                       NaT   \n",
       "18 2025-09-29 00:00:00-03:00                       NaT   \n",
       "19 2025-09-29 00:00:00-03:00                       NaT   \n",
       "20 2025-09-30 00:00:00-03:00                       NaT   \n",
       "21 2025-09-30 00:00:00-03:00                       NaT   \n",
       "22 2025-09-29 00:00:00-03:00                       NaT   \n",
       "23 2025-09-29 00:00:00-03:00                       NaT   \n",
       "24 2025-09-29 00:00:00-03:00                       NaT   \n",
       "25 2025-09-29 00:00:00-03:00                       NaT   \n",
       "26 2025-09-29 00:00:00-03:00                       NaT   \n",
       "27 2025-09-29 00:00:00-03:00                       NaT   \n",
       "28 2025-09-29 00:00:00-03:00                       NaT   \n",
       "29 2025-09-29 00:00:00-03:00                       NaT   \n",
       "\n",
       "                    fetch_to  days_missing      status  \n",
       "0  2025-09-29 00:00:00-03:00             3       delta  \n",
       "1  2025-09-29 00:00:00-03:00             3       delta  \n",
       "2  2025-09-29 00:00:00-03:00             3       delta  \n",
       "3  2025-09-29 00:00:00-03:00             3       delta  \n",
       "4  2025-09-29 00:00:00-03:00             3       delta  \n",
       "5  2025-09-29 00:00:00-03:00             3       delta  \n",
       "6  2025-09-29 00:00:00-03:00             3       delta  \n",
       "7  2025-09-29 00:00:00-03:00             3       delta  \n",
       "8  2025-09-29 00:00:00-03:00             3       delta  \n",
       "9  2025-09-29 00:00:00-03:00             3       delta  \n",
       "10 2025-09-29 00:00:00-03:00             3       delta  \n",
       "11 2025-09-29 00:00:00-03:00             3       delta  \n",
       "12 2025-09-29 00:00:00-03:00             3       delta  \n",
       "13 2025-09-29 00:00:00-03:00             3       delta  \n",
       "14                       NaT             0  up-to-date  \n",
       "15                       NaT             0  up-to-date  \n",
       "16                       NaT             0  up-to-date  \n",
       "17                       NaT             0  up-to-date  \n",
       "18                       NaT             0  up-to-date  \n",
       "19                       NaT             0  up-to-date  \n",
       "20                       NaT             0  up-to-date  \n",
       "21                       NaT             0  up-to-date  \n",
       "22                       NaT             0  up-to-date  \n",
       "23                       NaT             0  up-to-date  \n",
       "24                       NaT             0  up-to-date  \n",
       "25                       NaT             0  up-to-date  \n",
       "26                       NaT             0  up-to-date  \n",
       "27                       NaT             0  up-to-date  \n",
       "28                       NaT             0  up-to-date  \n",
       "29                       NaT             0  up-to-date  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvar relatório de delta em CSV e exibir resumo\n",
    "from datetime import datetime\n",
    "run_ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "out_csv = REPORTS_DIR / f'delta_ranges_{run_ts}.csv'\n",
    "delta_df_out = delta_df.copy()\n",
    "# Converter timestamps para string ISO (sem perder tz) para persistência\n",
    "for col in ['last_db_date','last_td_date','fetch_from','fetch_to']:\n",
    "    if col in delta_df_out:\n",
    "        delta_df_out[col] = delta_df_out[col].apply(lambda x: x.isoformat() if pd.notnull(x) else None)\n",
    "delta_df_out['cutoff_sp_date'] = cutoff_date\n",
    "delta_df_out.to_csv(out_csv, index=False, encoding='utf-8')\n",
    "print('Relatório salvo em:', out_csv)\n",
    "# Visualizar primeiros com problema de mapeamento/td e com delta\n",
    "cols = ['symbol','symbol_db','td_symbol','last_db_date','last_td_date','fetch_from','fetch_to','days_missing','status']\n",
    "view = delta_df[cols].copy()\n",
    "# Ordenar destaques: no-mapping/no-td-data primeiro, depois delta, depois up-to-date\n",
    "cat = pd.CategoricalDtype(categories=['no-mapping','no-td-data','delta','up-to-date'], ordered=True)\n",
    "view['status'] = view['status'].astype(cat)\n",
    "view = view.sort_values(['status','symbol']).reset_index(drop=True)\n",
    "view.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Símbolos esperados: 31\n",
      "Símbolos distintos no DB: 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "expected_symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "expected_db_symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "yf_ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "in_db",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "last_date",
         "rawType": "datetime64[ns, UTC-03:00]",
         "type": "unknown"
        }
       ],
       "ref": "bd8d433f-6099-405e-b023-72d71ff5cada",
       "rows": [
        [
         "0",
         "_bvsp",
         "bvsp",
         "^BVSP",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "1",
         "_gspc",
         "gspc",
         "^GSPC",
         "True",
         "2025-09-19 01:00:00-03:00"
        ],
        [
         "2",
         "_tnx",
         "tnx",
         "^TNX",
         "True",
         "2025-09-19 02:00:00-03:00"
        ],
        [
         "3",
         "_vix",
         "vix",
         "^VIX",
         "True",
         "2025-09-19 02:00:00-03:00"
        ],
        [
         "4",
         "abev3_sa",
         "abev3_sa",
         "ABEV3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "5",
         "b3sa3_sa",
         "b3sa3_sa",
         "B3SA3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "6",
         "bbas3_sa",
         "bbas3_sa",
         "BBAS3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "7",
         "bz=f",
         "bz=f",
         "BZ=F",
         "True",
         "2025-09-19 01:00:00-03:00"
        ],
        [
         "8",
         "cple6_sa",
         "cple6_sa",
         "CPLE6.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "9",
         "csna3_sa",
         "csna3_sa",
         "CSNA3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "10",
         "dx-y.nyb",
         "dx-y.nyb",
         "DX-Y.NYB",
         "True",
         "2025-09-19 01:00:00-03:00"
        ],
        [
         "11",
         "elet3_sa",
         "elet3_sa",
         "ELET3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "12",
         "ewz",
         "ewz",
         "EWZ",
         "True",
         "2025-09-19 01:00:00-03:00"
        ],
        [
         "13",
         "ggbr4_sa",
         "ggbr4_sa",
         "GGBR4.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "14",
         "hapv3_sa",
         "hapv3_sa",
         "HAPV3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "15",
         "itub4_sa",
         "itub4_sa",
         "ITUB4.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "16",
         "lren3_sa",
         "lren3_sa",
         "LREN3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "17",
         "petr4_sa",
         "petr4_sa",
         "PETR4.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "18",
         "prio3_sa",
         "prio3_sa",
         "PRIO3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "19",
         "pssa3_sa",
         "pssa3_sa",
         "PSSA3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "20",
         "rail3_sa",
         "rail3_sa",
         "RAIL3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "21",
         "rdor3_sa",
         "rdor3_sa",
         "RDOR3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "22",
         "sbsp3_sa",
         "sbsp3_sa",
         "SBSP3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "23",
         "suzb3_sa",
         "suzb3_sa",
         "SUZB3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "24",
         "taee11_sa",
         "taee11_sa",
         "TAEE11.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "25",
         "tims3_sa",
         "tims3_sa",
         "TIMS3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "26",
         "tots3_sa",
         "tots3_sa",
         "TOTS3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "27",
         "ugpa3_sa",
         "ugpa3_sa",
         "UGPA3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "28",
         "vale3_sa",
         "vale3_sa",
         "VALE3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "29",
         "vivt3_sa",
         "vivt3_sa",
         "VIVT3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ],
        [
         "30",
         "wege3_sa",
         "wege3_sa",
         "WEGE3.SA",
         "True",
         "2025-09-19 00:00:00-03:00"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 31
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected_symbol</th>\n",
       "      <th>expected_db_symbol</th>\n",
       "      <th>yf_ticker</th>\n",
       "      <th>in_db</th>\n",
       "      <th>last_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_bvsp</td>\n",
       "      <td>bvsp</td>\n",
       "      <td>^BVSP</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_gspc</td>\n",
       "      <td>gspc</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 01:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_tnx</td>\n",
       "      <td>tnx</td>\n",
       "      <td>^TNX</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 02:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_vix</td>\n",
       "      <td>vix</td>\n",
       "      <td>^VIX</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 02:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abev3_sa</td>\n",
       "      <td>abev3_sa</td>\n",
       "      <td>ABEV3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b3sa3_sa</td>\n",
       "      <td>b3sa3_sa</td>\n",
       "      <td>B3SA3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bbas3_sa</td>\n",
       "      <td>bbas3_sa</td>\n",
       "      <td>BBAS3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bz=f</td>\n",
       "      <td>bz=f</td>\n",
       "      <td>BZ=F</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 01:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cple6_sa</td>\n",
       "      <td>cple6_sa</td>\n",
       "      <td>CPLE6.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>csna3_sa</td>\n",
       "      <td>csna3_sa</td>\n",
       "      <td>CSNA3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dx-y.nyb</td>\n",
       "      <td>dx-y.nyb</td>\n",
       "      <td>DX-Y.NYB</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 01:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>elet3_sa</td>\n",
       "      <td>elet3_sa</td>\n",
       "      <td>ELET3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ewz</td>\n",
       "      <td>ewz</td>\n",
       "      <td>EWZ</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 01:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ggbr4_sa</td>\n",
       "      <td>ggbr4_sa</td>\n",
       "      <td>GGBR4.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hapv3_sa</td>\n",
       "      <td>hapv3_sa</td>\n",
       "      <td>HAPV3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>itub4_sa</td>\n",
       "      <td>itub4_sa</td>\n",
       "      <td>ITUB4.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lren3_sa</td>\n",
       "      <td>lren3_sa</td>\n",
       "      <td>LREN3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>PETR4.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>prio3_sa</td>\n",
       "      <td>prio3_sa</td>\n",
       "      <td>PRIO3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pssa3_sa</td>\n",
       "      <td>pssa3_sa</td>\n",
       "      <td>PSSA3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rail3_sa</td>\n",
       "      <td>rail3_sa</td>\n",
       "      <td>RAIL3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rdor3_sa</td>\n",
       "      <td>rdor3_sa</td>\n",
       "      <td>RDOR3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sbsp3_sa</td>\n",
       "      <td>sbsp3_sa</td>\n",
       "      <td>SBSP3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>suzb3_sa</td>\n",
       "      <td>suzb3_sa</td>\n",
       "      <td>SUZB3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>taee11_sa</td>\n",
       "      <td>taee11_sa</td>\n",
       "      <td>TAEE11.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tims3_sa</td>\n",
       "      <td>tims3_sa</td>\n",
       "      <td>TIMS3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tots3_sa</td>\n",
       "      <td>tots3_sa</td>\n",
       "      <td>TOTS3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ugpa3_sa</td>\n",
       "      <td>ugpa3_sa</td>\n",
       "      <td>UGPA3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vale3_sa</td>\n",
       "      <td>vale3_sa</td>\n",
       "      <td>VALE3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>vivt3_sa</td>\n",
       "      <td>vivt3_sa</td>\n",
       "      <td>VIVT3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>wege3_sa</td>\n",
       "      <td>wege3_sa</td>\n",
       "      <td>WEGE3.SA</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-09-19 00:00:00-03:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   expected_symbol expected_db_symbol  yf_ticker  in_db  \\\n",
       "0            _bvsp               bvsp      ^BVSP   True   \n",
       "1            _gspc               gspc      ^GSPC   True   \n",
       "2             _tnx                tnx       ^TNX   True   \n",
       "3             _vix                vix       ^VIX   True   \n",
       "4         abev3_sa           abev3_sa   ABEV3.SA   True   \n",
       "5         b3sa3_sa           b3sa3_sa   B3SA3.SA   True   \n",
       "6         bbas3_sa           bbas3_sa   BBAS3.SA   True   \n",
       "7             bz=f               bz=f       BZ=F   True   \n",
       "8         cple6_sa           cple6_sa   CPLE6.SA   True   \n",
       "9         csna3_sa           csna3_sa   CSNA3.SA   True   \n",
       "10        dx-y.nyb           dx-y.nyb   DX-Y.NYB   True   \n",
       "11        elet3_sa           elet3_sa   ELET3.SA   True   \n",
       "12             ewz                ewz        EWZ   True   \n",
       "13        ggbr4_sa           ggbr4_sa   GGBR4.SA   True   \n",
       "14        hapv3_sa           hapv3_sa   HAPV3.SA   True   \n",
       "15        itub4_sa           itub4_sa   ITUB4.SA   True   \n",
       "16        lren3_sa           lren3_sa   LREN3.SA   True   \n",
       "17        petr4_sa           petr4_sa   PETR4.SA   True   \n",
       "18        prio3_sa           prio3_sa   PRIO3.SA   True   \n",
       "19        pssa3_sa           pssa3_sa   PSSA3.SA   True   \n",
       "20        rail3_sa           rail3_sa   RAIL3.SA   True   \n",
       "21        rdor3_sa           rdor3_sa   RDOR3.SA   True   \n",
       "22        sbsp3_sa           sbsp3_sa   SBSP3.SA   True   \n",
       "23        suzb3_sa           suzb3_sa   SUZB3.SA   True   \n",
       "24       taee11_sa          taee11_sa  TAEE11.SA   True   \n",
       "25        tims3_sa           tims3_sa   TIMS3.SA   True   \n",
       "26        tots3_sa           tots3_sa   TOTS3.SA   True   \n",
       "27        ugpa3_sa           ugpa3_sa   UGPA3.SA   True   \n",
       "28        vale3_sa           vale3_sa   VALE3.SA   True   \n",
       "29        vivt3_sa           vivt3_sa   VIVT3.SA   True   \n",
       "30        wege3_sa           wege3_sa   WEGE3.SA   True   \n",
       "\n",
       "                   last_date  \n",
       "0  2025-09-19 00:00:00-03:00  \n",
       "1  2025-09-19 01:00:00-03:00  \n",
       "2  2025-09-19 02:00:00-03:00  \n",
       "3  2025-09-19 02:00:00-03:00  \n",
       "4  2025-09-19 00:00:00-03:00  \n",
       "5  2025-09-19 00:00:00-03:00  \n",
       "6  2025-09-19 00:00:00-03:00  \n",
       "7  2025-09-19 01:00:00-03:00  \n",
       "8  2025-09-19 00:00:00-03:00  \n",
       "9  2025-09-19 00:00:00-03:00  \n",
       "10 2025-09-19 01:00:00-03:00  \n",
       "11 2025-09-19 00:00:00-03:00  \n",
       "12 2025-09-19 01:00:00-03:00  \n",
       "13 2025-09-19 00:00:00-03:00  \n",
       "14 2025-09-19 00:00:00-03:00  \n",
       "15 2025-09-19 00:00:00-03:00  \n",
       "16 2025-09-19 00:00:00-03:00  \n",
       "17 2025-09-19 00:00:00-03:00  \n",
       "18 2025-09-19 00:00:00-03:00  \n",
       "19 2025-09-19 00:00:00-03:00  \n",
       "20 2025-09-19 00:00:00-03:00  \n",
       "21 2025-09-19 00:00:00-03:00  \n",
       "22 2025-09-19 00:00:00-03:00  \n",
       "23 2025-09-19 00:00:00-03:00  \n",
       "24 2025-09-19 00:00:00-03:00  \n",
       "25 2025-09-19 00:00:00-03:00  \n",
       "26 2025-09-19 00:00:00-03:00  \n",
       "27 2025-09-19 00:00:00-03:00  \n",
       "28 2025-09-19 00:00:00-03:00  \n",
       "29 2025-09-19 00:00:00-03:00  \n",
       "30 2025-09-19 00:00:00-03:00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diagnóstico: comparar símbolos esperados vs símbolos no DB e verificar últimas datas\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "expected_syms = SYMBOLS\n",
    "expected_db_syms = [to_db_symbol(s) for s in expected_syms]\n",
    "expected_map = pd.DataFrame({\n",
    "    'expected_symbol': expected_syms,\n",
    "    'expected_db_symbol': expected_db_syms,\n",
    "    'td_symbol': [TD_MAP.get(s) for s in expected_syms],\n",
    "})\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    db_syms = pd.read_sql(text(\"SELECT DISTINCT symbol FROM ohlcv_daily ORDER BY symbol\"), conn)\n",
    "    last_dates = pd.read_sql(text(\"SELECT symbol, MAX(date) AS last_date FROM ohlcv_daily GROUP BY symbol\"), conn)\n",
    "\n",
    "db_syms['symbol'] = db_syms['symbol'].astype(str)\n",
    "last_dates['symbol'] = last_dates['symbol'].astype(str)\n",
    "\n",
    "diag = expected_map.merge(db_syms.rename(columns={'symbol':'in_db_symbol'}),\n",
    "                            left_on='expected_db_symbol', right_on='in_db_symbol', how='left')\n",
    "diag = diag.merge(last_dates, left_on='expected_db_symbol', right_on='symbol', how='left', suffixes=('','_dup'))\n",
    "diag = diag.drop(columns=[c for c in ['symbol'] if c in diag.columns])\n",
    "diag['in_db'] = diag['in_db_symbol'].notna()\n",
    "diag['last_date'] = pd.to_datetime(diag['last_date'], errors='coerce')\n",
    "diag = diag.sort_values(['in_db','expected_symbol'], ascending=[True, True]).reset_index(drop=True)\n",
    "print('Símbolos esperados:', len(expected_syms))\n",
    "print('Símbolos distintos no DB:', db_syms.shape[0])\n",
    "diag[['expected_symbol','expected_db_symbol','td_symbol','in_db','last_date']].head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestão incremental — persistir deltas no DB\n",
    "\n",
    "> Esta seção baixa somente as janelas [fetch_from, fetch_to] de cada símbolo, normaliza `Date` para tz `America/Sao_Paulo`, aplica deduplicação e realiza upsert em `ohlcv_daily`. Em seguida, gera um resumo do estado do banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers de normalização e upsert\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import text\n",
    "\n",
    "def ensure_tz_sp_series(s: pd.Series) -> pd.Series:\n",
    "    s = pd.to_datetime(s, errors='coerce', utc=False)\n",
    "    if isinstance(s.dtype, pd.DatetimeTZDtype):\n",
    "        return s.dt.tz_convert('America/Sao_Paulo')\n",
    "    else:\n",
    "        return s.dt.tz_localize('America/Sao_Paulo')\n",
    "\n",
    "def df_to_rows_for_db(df: pd.DataFrame) -> list[dict]:\n",
    "    # Garante colunas obrigatórias\n",
    "    cols = ['Symbol','Date','Open','High','Low','Close','Adj Close','Volume','Dividends','Stock Splits']\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "\n",
    "    # Normaliza Date para tz America/Sao_Paulo\n",
    "    dt = df['Date']\n",
    "    if not isinstance(dt.dtype, pd.DatetimeTZDtype):\n",
    "        dt = pd.to_datetime(dt, errors='coerce').dt.tz_localize('America/Sao_Paulo')\n",
    "    else:\n",
    "        dt = dt.dt.tz_convert('America/Sao_Paulo')\n",
    "    date_iso = dt.apply(lambda x: x.isoformat() if pd.notnull(x) else None)\n",
    "\n",
    "    tmp = df.copy()\n",
    "    symbol_db = tmp['Symbol'].astype(str).str.lower().str.lstrip('_')\n",
    "    mask = date_iso.notna()\n",
    "    if not mask.any():\n",
    "        return []\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        'symbol': symbol_db[mask],\n",
    "        'date': date_iso[mask],\n",
    "        'open': pd.to_numeric(tmp.loc[mask, 'Open'], errors='coerce'),\n",
    "        'high': pd.to_numeric(tmp.loc[mask, 'High'], errors='coerce'),\n",
    "        'low': pd.to_numeric(tmp.loc[mask, 'Low'], errors='coerce'),\n",
    "        'close': pd.to_numeric(tmp.loc[mask, 'Close'], errors='coerce'),\n",
    "        'adj_close': pd.to_numeric(tmp.loc[mask, 'Adj Close'], errors='coerce'),\n",
    "        'volume': pd.to_numeric(tmp.loc[mask, 'Volume'], errors='coerce').astype('Int64'),\n",
    "        'dividends': pd.to_numeric(tmp.loc[mask, 'Dividends'], errors='coerce'),\n",
    "        'stock_splits': pd.to_numeric(tmp.loc[mask, 'Stock Splits'], errors='coerce'),\n",
    "    })\n",
    "    out = out.astype(object).where(pd.notnull(out), None)\n",
    "    # Deduplicar por (symbol, date) por segurança\n",
    "    out = out.sort_values(['symbol','date']).drop_duplicates(['symbol','date'], keep='last')\n",
    "    return out.to_dict(orient='records')\n",
    "\n",
    "\n",
    "dialect = sa.create_engine(DB_URL).dialect.name\n",
    "is_pg = (dialect == 'postgresql')\n",
    "if is_pg:\n",
    "    UPSERT_SQL = text(\"\"\"\n",
    "        INSERT INTO ohlcv_daily (symbol, date, open, high, low, close, adj_close, volume, dividends, stock_splits)\n",
    "        VALUES (:symbol, :date, :open, :high, :low, :close, :adj_close, :volume, :dividends, :stock_splits)\n",
    "        ON CONFLICT (symbol, date) DO UPDATE SET\n",
    "            open=EXCLUDED.open,\n",
    "            high=EXCLUDED.high,\n",
    "            low=EXCLUDED.low,\n",
    "            close=EXCLUDED.close,\n",
    "            adj_close=EXCLUDED.adj_close,\n",
    "            volume=EXCLUDED.volume,\n",
    "            dividends=EXCLUDED.dividends,\n",
    "            stock_splits=EXCLUDED.stock_splits\n",
    "    \"\"\")\n",
    "else:\n",
    "    UPSERT_SQL = text(\"\"\"\n",
    "        INSERT OR REPLACE INTO ohlcv_daily (symbol, date, open, high, low, close, adj_close, volume, dividends, stock_splits)\n",
    "        VALUES (:symbol, :date, :open, :high, :low, :close, :adj_close, :volume, :dividends, :stock_splits)\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['ABEV3.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['CPLE6.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['CSNA3.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['ELET3.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['GGBR4.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['HAPV3.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['RAIL3.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['RDOR3.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['SUZB3.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['TAEE11.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['UGPA3.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['VALE3.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['VIVT3.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n",
      "\n",
      "1 Failed download:\n",
      "['WEGE3.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-09-27 -> 2025-09-30)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestão concluída.\n",
      "Símbolos com dados inseridos: 0\n",
      "Falhas: 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [('abev3_sa', 'empty-download'),\n",
       "  ('cple6_sa', 'empty-download'),\n",
       "  ('csna3_sa', 'empty-download'),\n",
       "  ('elet3_sa', 'empty-download'),\n",
       "  ('ggbr4_sa', 'empty-download'),\n",
       "  ('hapv3_sa', 'empty-download'),\n",
       "  ('rail3_sa', 'empty-download'),\n",
       "  ('rdor3_sa', 'empty-download'),\n",
       "  ('suzb3_sa', 'empty-download'),\n",
       "  ('taee11_sa', 'empty-download')])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ingestão incremental com base em delta_df (via Twelve Data)\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "ingested = []\n",
    "failed = []\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for _, r in delta_df.iterrows():\n",
    "        sym = r['symbol']\n",
    "        sym_db = r['symbol_db'] if 'symbol_db' in r else to_db_symbol(sym)\n",
    "        td_sym = r.get('td_symbol')\n",
    "        ffrom = r['fetch_from']\n",
    "        fto = r['fetch_to']\n",
    "        status = r['status']\n",
    "        if status != 'delta' or pd.isna(ffrom) or pd.isna(fto) or not td_sym:\n",
    "            continue\n",
    "        try:\n",
    "            start_str = pd.Timestamp(ffrom).date().strftime('%Y-%m-%d')\n",
    "            end_str = pd.Timestamp(fto).date().strftime('%Y-%m-%d')\n",
    "            df = td_download_range(td_sym, start_str, end_str)\n",
    "            if df is None or df.empty:\n",
    "                failed.append((sym, 'empty-download'))\n",
    "                continue\n",
    "            # Padronizar colunas esperadas\n",
    "            for c in ['Open','High','Low','Close','Adj Close','Volume','Dividends','Stock Splits']:\n",
    "                if c not in df.columns:\n",
    "                    if c == 'Adj Close' and 'Close' in df.columns:\n",
    "                        df[c] = df['Close']\n",
    "                    else:\n",
    "                        df[c] = pd.NA\n",
    "\n",
    "            dt = df['Date']\n",
    "            if not isinstance(dt.dtype, pd.DatetimeTZDtype):\n",
    "                dt = pd.to_datetime(dt, errors='coerce').dt.tz_localize('America/Sao_Paulo')\n",
    "            else:\n",
    "                dt = dt.dt.tz_convert('America/Sao_Paulo')\n",
    "            date_iso = dt.apply(lambda x: x.isoformat() if pd.notnull(x) else None)\n",
    "\n",
    "            rows_df = pd.DataFrame({\n",
    "                'symbol': pd.Series([sym_db]*len(df)),\n",
    "                'date': date_iso,\n",
    "                'open': pd.to_numeric(df['Open'], errors='coerce'),\n",
    "                'high': pd.to_numeric(df['High'], errors='coerce'),\n",
    "                'low': pd.to_numeric(df['Low'], errors='coerce'),\n",
    "                'close': pd.to_numeric(df['Close'], errors='coerce'),\n",
    "                'adj_close': pd.to_numeric(df['Adj Close'], errors='coerce'),\n",
    "                'volume': pd.to_numeric(df['Volume'], errors='coerce').astype('Int64'),\n",
    "                'dividends': pd.to_numeric(df['Dividends'], errors='coerce'),\n",
    "                'stock_splits': pd.to_numeric(df['Stock Splits'], errors='coerce'),\n",
    "            })\n",
    "            rows_df = rows_df.astype(object).where(pd.notnull(rows_df), None)\n",
    "            rows_df = rows_df.dropna(subset=['date'])\n",
    "            if rows_df.empty:\n",
    "                failed.append((sym, 'no-valid-dates'))\n",
    "                continue\n",
    "            rows_df = rows_df.sort_values(['symbol','date']).drop_duplicates(['symbol','date'], keep='last')\n",
    "            rows = rows_df.to_dict(orient='records')\n",
    "            if rows:\n",
    "                conn.execute(UPSERT_SQL, rows)\n",
    "                ingested.append((sym, len(rows)))\n",
    "        except Exception as e:\n",
    "            failed.append((sym, str(e)))\n",
    "\n",
    "print('Ingestão concluída (Twelve Data).')\n",
    "print('Símbolos com dados inseridos:', len(ingested))\n",
    "print('Falhas:', len(failed))\n",
    "ingested[:10], failed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff SP (data): 2025-09-30\n",
      "Linhas além do cutoff (mostrando até 100): 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "9a0d15ca-4502-422a-9d00-f94437a8fbd0",
       "rows": [],
       "shape": {
        "columns": 2,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [symbol, date]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remoção não executada (confirm=False) ou nenhuma linha a remover.\n"
     ]
    }
   ],
   "source": [
    "# Limpeza opcional: remover linhas além do cutoff (datas futuras em relação ao ontem SP)\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "confirm = True  # mude para False se quiser apenas ver o que seria removido\n",
    "\n",
    "cutoff_date_str = cutoff_date.strftime('%Y-%m-%d')\n",
    "print('Cutoff SP (data):', cutoff_date_str)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    preview = pd.read_sql(text(\"\"\"\n",
    "        SELECT symbol, date\n",
    "        FROM ohlcv_daily\n",
    "        WHERE substr(date,1,10) > :cut\n",
    "        ORDER BY symbol, date\n",
    "        LIMIT 100\n",
    "    \"\"\"), conn, params={'cut': cutoff_date_str})\n",
    "\n",
    "print('Linhas além do cutoff (mostrando até 100):', len(preview))\n",
    "display(preview.head(20))  # Mostra o DataFrame no notebook\n",
    "\n",
    "if confirm and not preview.empty:\n",
    "    with engine.begin() as conn2:\n",
    "        conn2.execute(text(\"DELETE FROM ohlcv_daily WHERE substr(date,1,10) > :cut\"), {'cut': cutoff_date_str})\n",
    "    print('Remoção executada para datas acima de', cutoff_date_str)\n",
    "else:\n",
    "    print('Remoção não executada (confirm=False) ou nenhuma linha a remover.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas no banco: 101473\n",
      "Símbolos carregados: 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "min_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_date",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "83357005-b237-4468-b48a-8835098488c6",
       "rows": [
        [
         "0",
         "abev3_sa",
         "3414",
         "2012-01-02T00:00:00-02:00",
         "2025-09-26T00:00:00-03:00"
        ],
        [
         "1",
         "b3sa3_sa",
         "3415",
         "2012-01-02T00:00:00-02:00",
         "2025-09-29T00:00:00-03:00"
        ],
        [
         "2",
         "bbas3_sa",
         "3415",
         "2012-01-02T00:00:00-02:00",
         "2025-09-29T00:00:00-03:00"
        ],
        [
         "3",
         "bvsp",
         "3406",
         "2012-01-03T00:00:00-02:00",
         "2025-09-29T00:00:00-03:00"
        ],
        [
         "4",
         "bz=f",
         "3439",
         "2012-01-03T03:00:00-02:00",
         "2025-09-30T00:00:00-03:00"
        ],
        [
         "5",
         "cple6_sa",
         "3413",
         "2012-01-02T00:00:00-02:00",
         "2025-09-26T00:00:00-03:00"
        ],
        [
         "6",
         "csna3_sa",
         "3414",
         "2012-01-02T00:00:00-02:00",
         "2025-09-26T00:00:00-03:00"
        ],
        [
         "7",
         "dx-y.nyb",
         "3457",
         "2012-01-03T03:00:00-02:00",
         "2025-09-30T00:00:00-03:00"
        ],
        [
         "8",
         "elet3_sa",
         "3414",
         "2012-01-02T00:00:00-02:00",
         "2025-09-26T00:00:00-03:00"
        ],
        [
         "9",
         "ewz",
         "3455",
         "2012-01-03T03:00:00-02:00",
         "2025-09-29T00:00:00-03:00"
        ],
        [
         "10",
         "ggbr4_sa",
         "3414",
         "2012-01-02T00:00:00-02:00",
         "2025-09-26T00:00:00-03:00"
        ],
        [
         "11",
         "gspc",
         "3455",
         "2012-01-03T03:00:00-02:00",
         "2025-09-29T00:00:00-03:00"
        ],
        [
         "12",
         "hapv3_sa",
         "1845",
         "2018-04-26T00:00:00-03:00",
         "2025-09-26T00:00:00-03:00"
        ],
        [
         "13",
         "itub4_sa",
         "3415",
         "2012-01-02T00:00:00-02:00",
         "2025-09-29T00:00:00-03:00"
        ],
        [
         "14",
         "lren3_sa",
         "3415",
         "2012-01-02T00:00:00-02:00",
         "2025-09-29T00:00:00-03:00"
        ],
        [
         "15",
         "petr4_sa",
         "3415",
         "2012-01-02T00:00:00-02:00",
         "2025-09-29T00:00:00-03:00"
        ],
        [
         "16",
         "prio3_sa",
         "3415",
         "2012-01-02T00:00:00-02:00",
         "2025-09-29T00:00:00-03:00"
        ],
        [
         "17",
         "pssa3_sa",
         "3415",
         "2012-01-02T00:00:00-02:00",
         "2025-09-29T00:00:00-03:00"
        ],
        [
         "18",
         "rail3_sa",
         "2611",
         "2015-04-02T00:00:00-03:00",
         "2025-09-26T00:00:00-03:00"
        ],
        [
         "19",
         "rdor3_sa",
         "1192",
         "2020-12-15T00:00:00-03:00",
         "2025-09-26T00:00:00-03:00"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>n</th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abev3_sa</td>\n",
       "      <td>3414</td>\n",
       "      <td>2012-01-02T00:00:00-02:00</td>\n",
       "      <td>2025-09-26T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b3sa3_sa</td>\n",
       "      <td>3415</td>\n",
       "      <td>2012-01-02T00:00:00-02:00</td>\n",
       "      <td>2025-09-29T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bbas3_sa</td>\n",
       "      <td>3415</td>\n",
       "      <td>2012-01-02T00:00:00-02:00</td>\n",
       "      <td>2025-09-29T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bvsp</td>\n",
       "      <td>3406</td>\n",
       "      <td>2012-01-03T00:00:00-02:00</td>\n",
       "      <td>2025-09-29T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bz=f</td>\n",
       "      <td>3439</td>\n",
       "      <td>2012-01-03T03:00:00-02:00</td>\n",
       "      <td>2025-09-30T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cple6_sa</td>\n",
       "      <td>3413</td>\n",
       "      <td>2012-01-02T00:00:00-02:00</td>\n",
       "      <td>2025-09-26T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>csna3_sa</td>\n",
       "      <td>3414</td>\n",
       "      <td>2012-01-02T00:00:00-02:00</td>\n",
       "      <td>2025-09-26T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dx-y.nyb</td>\n",
       "      <td>3457</td>\n",
       "      <td>2012-01-03T03:00:00-02:00</td>\n",
       "      <td>2025-09-30T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>elet3_sa</td>\n",
       "      <td>3414</td>\n",
       "      <td>2012-01-02T00:00:00-02:00</td>\n",
       "      <td>2025-09-26T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ewz</td>\n",
       "      <td>3455</td>\n",
       "      <td>2012-01-03T03:00:00-02:00</td>\n",
       "      <td>2025-09-29T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ggbr4_sa</td>\n",
       "      <td>3414</td>\n",
       "      <td>2012-01-02T00:00:00-02:00</td>\n",
       "      <td>2025-09-26T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gspc</td>\n",
       "      <td>3455</td>\n",
       "      <td>2012-01-03T03:00:00-02:00</td>\n",
       "      <td>2025-09-29T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hapv3_sa</td>\n",
       "      <td>1845</td>\n",
       "      <td>2018-04-26T00:00:00-03:00</td>\n",
       "      <td>2025-09-26T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itub4_sa</td>\n",
       "      <td>3415</td>\n",
       "      <td>2012-01-02T00:00:00-02:00</td>\n",
       "      <td>2025-09-29T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lren3_sa</td>\n",
       "      <td>3415</td>\n",
       "      <td>2012-01-02T00:00:00-02:00</td>\n",
       "      <td>2025-09-29T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>3415</td>\n",
       "      <td>2012-01-02T00:00:00-02:00</td>\n",
       "      <td>2025-09-29T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>prio3_sa</td>\n",
       "      <td>3415</td>\n",
       "      <td>2012-01-02T00:00:00-02:00</td>\n",
       "      <td>2025-09-29T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pssa3_sa</td>\n",
       "      <td>3415</td>\n",
       "      <td>2012-01-02T00:00:00-02:00</td>\n",
       "      <td>2025-09-29T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rail3_sa</td>\n",
       "      <td>2611</td>\n",
       "      <td>2015-04-02T00:00:00-03:00</td>\n",
       "      <td>2025-09-26T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rdor3_sa</td>\n",
       "      <td>1192</td>\n",
       "      <td>2020-12-15T00:00:00-03:00</td>\n",
       "      <td>2025-09-26T00:00:00-03:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      symbol     n                   min_date                   max_date\n",
       "0   abev3_sa  3414  2012-01-02T00:00:00-02:00  2025-09-26T00:00:00-03:00\n",
       "1   b3sa3_sa  3415  2012-01-02T00:00:00-02:00  2025-09-29T00:00:00-03:00\n",
       "2   bbas3_sa  3415  2012-01-02T00:00:00-02:00  2025-09-29T00:00:00-03:00\n",
       "3       bvsp  3406  2012-01-03T00:00:00-02:00  2025-09-29T00:00:00-03:00\n",
       "4       bz=f  3439  2012-01-03T03:00:00-02:00  2025-09-30T00:00:00-03:00\n",
       "5   cple6_sa  3413  2012-01-02T00:00:00-02:00  2025-09-26T00:00:00-03:00\n",
       "6   csna3_sa  3414  2012-01-02T00:00:00-02:00  2025-09-26T00:00:00-03:00\n",
       "7   dx-y.nyb  3457  2012-01-03T03:00:00-02:00  2025-09-30T00:00:00-03:00\n",
       "8   elet3_sa  3414  2012-01-02T00:00:00-02:00  2025-09-26T00:00:00-03:00\n",
       "9        ewz  3455  2012-01-03T03:00:00-02:00  2025-09-29T00:00:00-03:00\n",
       "10  ggbr4_sa  3414  2012-01-02T00:00:00-02:00  2025-09-26T00:00:00-03:00\n",
       "11      gspc  3455  2012-01-03T03:00:00-02:00  2025-09-29T00:00:00-03:00\n",
       "12  hapv3_sa  1845  2018-04-26T00:00:00-03:00  2025-09-26T00:00:00-03:00\n",
       "13  itub4_sa  3415  2012-01-02T00:00:00-02:00  2025-09-29T00:00:00-03:00\n",
       "14  lren3_sa  3415  2012-01-02T00:00:00-02:00  2025-09-29T00:00:00-03:00\n",
       "15  petr4_sa  3415  2012-01-02T00:00:00-02:00  2025-09-29T00:00:00-03:00\n",
       "16  prio3_sa  3415  2012-01-02T00:00:00-02:00  2025-09-29T00:00:00-03:00\n",
       "17  pssa3_sa  3415  2012-01-02T00:00:00-02:00  2025-09-29T00:00:00-03:00\n",
       "18  rail3_sa  2611  2015-04-02T00:00:00-03:00  2025-09-26T00:00:00-03:00\n",
       "19  rdor3_sa  1192  2020-12-15T00:00:00-03:00  2025-09-26T00:00:00-03:00"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relato do estado do banco após ingestão\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    total = conn.execute(text('SELECT COUNT(*) FROM ohlcv_daily')).scalar_one()\n",
    "    by_symbol = pd.read_sql(text(\"\"\"\n",
    "        SELECT symbol, COUNT(*) AS n, MIN(date) AS min_date, MAX(date) AS max_date\n",
    "        FROM ohlcv_daily\n",
    "        GROUP BY symbol\n",
    "        ORDER BY symbol\n",
    "    \"\"\"), conn)\n",
    "\n",
    "print('Total de linhas no banco:', total)\n",
    "print('Símbolos carregados:', len(by_symbol))\n",
    "by_symbol.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarized conversation historyI'll first add a short diagnostic step to compute max dates per symbol as local dates and verify inconsistencies, then propose and implement a fix to clamp ingestion to the previous local business day and clean any future-dated rows, followed by rerunning the status cell. I'll keep you updated after these reads and edits. \n",
    "\n",
    "Added 2 todos\n",
    "\n",
    "To diagnose and then fix the inconsistent max_date, I'll insert diagnostic and cleanup cells, edit the delta calculation to cap fetch_to at \"yesterday in São Paulo,\" and then run the cleanup and re-check cells to confirm alignment. \n",
    "\n",
    "Retrieving Notebook summary.\n",
    "\n",
    "Adding a diagnostic cell and updating delta logic to cap fetch_to at \"yesterday in São Paulo\", plus a cleanup cell to remove rows beyond the cutoff, then I'll run the cleanup and re-run ingestion and status to confirm uniform max_date. \n",
    "\n",
    "Editing notebook\n",
    "\n",
    "Editing notebook\n",
    "\n",
    "Editing notebook\n",
    "\n",
    "Editing notebook\n",
    "\n",
    "Starting (2/4) *Clamp fetch_to to yesterday (SP)*\n",
    "\n",
    "Ran [](vscode-notebook-cell:/g%3A/Drives%20compartilhados/BOLSA_2026/a_bolsa2026_gemini/01_notebooks/estrutura_e_ingesta.ipynb#X23sZmlsZQ%3D%3D)\n",
    "\n",
    "Ran [](vscode-notebook-cell:/g%3A/Drives%20compartilhados/BOLSA_2026/a_bolsa2026_gemini/01_notebooks/estrutura_e_ingesta.ipynb#X24sZmlsZQ%3D%3D)\n",
    "\n",
    "Ran [](vscode-notebook-cell:/g%3A/Drives%20compartilhados/BOLSA_2026/a_bolsa2026_gemini/01_notebooks/estrutura_e_ingesta.ipynb#X35sZmlsZQ%3D%3D)\n",
    "\n",
    "Ran [](vscode-notebook-cell:/g%3A/Drives%20compartilhados/BOLSA_2026/a_bolsa2026_gemini/01_notebooks/estrutura_e_ingesta.ipynb#X31sZmlsZQ%3D%3D)\n",
    "\n",
    "Ran [](vscode-notebook-cell:/g%3A/Drives%20compartilhados/BOLSA_2026/a_bolsa2026_gemini/01_notebooks/estrutura_e_ingesta.ipynb#X34sZmlsZQ%3D%3D)\n",
    "\n",
    "Completed (2/4) *Clamp fetch_to to yesterday (SP)*\n",
    "\n",
    "Estou vendo a saída mais recente e a divergência de max_date entre tickers é real. Eu já rodei um diagnóstico e ajustei a rotina para não mirar além de “ontem SP” e chequei o banco. Eis o que encontramos e por quê os tickers não alinharam em 30/09/2025:\n",
    "\n",
    "## O que aconteceu\n",
    "\n",
    "- Distribuição das últimas datas no banco (convertidas para America/Sao_Paulo):\n",
    "  - 2025-09-26: 14 símbolos\n",
    "  - 2025-09-29: 14 símbolos\n",
    "  - 2025-09-30: 3 símbolos\n",
    "\n",
    "- Reingestão dos deltas até “ontem SP” (2025-09-30) falhou para vários tickers .SA com downloads vazios:\n",
    "  - Mensagem típica do yfinance: “possibly delisted; no price data found (1d 2025-09-27 -> 2025-09-30)”.\n",
    "  - Ou seja, a fonte (Yahoo Finance) não devolveu candles para o período, apesar de não ser feriado.\n",
    "\n",
    "- Conferência de “datas no futuro”:\n",
    "  - Adicionei uma limpeza opcional para remover linhas > 2025-09-30; o preview mostrou 0 linhas, então não foi problema de timezone empurrando para o dia seguinte.\n",
    "\n",
    "Resumo: a falha não foi na normalização de timezone nem em end-date inclusivo. É latência/indisponibilidade de dados no Yahoo para vários tickers da B3 no momento da execução. Por isso alguns ficaram em 26/09 (sexta), outros em 29/09 (segunda) e poucos chegaram a 30/09. Essa diferença de “janela de atualização” entre bolsas/ativos no Yahoo é comum.\n",
    "\n",
    "## Correções já aplicadas\n",
    "\n",
    "- Cap do fetch_to: agora limitamos a busca a “ontem em São Paulo”, para evitar assimetrias por datas futuras.\n",
    "- Verificação e limpeza de linhas acima do cutoff (nenhuma remoção foi necessária).\n",
    "- Reexecução de ingestão com o novo cutoff: os .SA seguiram sem dados no Yahoo para 29–30/09 no momento da execução (empty-download).\n",
    "\n",
    "## Como garantir todos em 30/09 de forma robusta\n",
    "\n",
    "Se o requisito é “todos os símbolos devem fechar na mesma data (ontem) sempre que não houver feriado local”, você precisa neutralizar a latência de atualização da fonte:\n",
    "\n",
    "- Calendário por bolsa + hora de execução:\n",
    "  - Determinar o “último dia útil esperado” por bolsa (ex.: B3 vs NYSE) e rodar a ingestão após o horário em que o Yahoo costuma publicar os fechamentos da B3 (ex.: 21h–23h BRT), com 1–2 tentativas automáticas de reprocessamento.\n",
    "- Tentar novamente (retry/backfill):\n",
    "  - Se o download veio vazio, reprogramar tentativas (ex.: a cada 30 min) até alcançar a data-alvo do calendário, e só então fechar o dia.\n",
    "- Fonte alternativa (opcional):\n",
    "  - Se o SLA precisa ser D+0 rígido, considere uma fonte com menor latência para B3 (ex.: feed oficial B3, serviços pagos, ou outra API que atualize mais cedo que o Yahoo). Também dá para usar um “mix”: yfinance como base e fallback alternativo em D+0.\n",
    "- Alertas:\n",
    "  - Emitir relatório quando algum ticker esperado para a data-alvo vier vazio, para acompanhamento.\n",
    "\n",
    "Posso implementar já:\n",
    "- Um calendário simples (B3 x EUA) para estimar a data-alvo por bolsa.\n",
    "- Uma janela de execução/retentativa para garantir que todos atinjam a mesma max_date.\n",
    "- Um alerta/relatório destacando quais tickers ainda não atualizaram e quando reprocessar.\n",
    "\n",
    "Se quiser, sigo com essa implementação agora e deixo a rotina automática para assegurar que todos fechem em 30/09/2025 (e nos próximos dias) de forma consistente.\n",
    "\n",
    "Made changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperado (ontem SP): 2025-09-30\n",
      "Distribuição de max_date_sp:\n",
      "max_date_sp\n",
      "2025-09-26    14\n",
      "2025-09-29    14\n",
      "2025-09-30     3\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "max_date_iso",
         "rawType": "datetime64[ns, UTC-03:00]",
         "type": "unknown"
        },
        {
         "name": "max_date_sp",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "be92a2e5-0643-4c10-ae9e-c22509c47cae",
       "rows": [
        [
         "0",
         "abev3_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "1",
         "b3sa3_sa",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "2",
         "bbas3_sa",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "3",
         "bvsp",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "5",
         "cple6_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "6",
         "csna3_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "8",
         "elet3_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "9",
         "ewz",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "10",
         "ggbr4_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "11",
         "gspc",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "12",
         "hapv3_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "13",
         "itub4_sa",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "14",
         "lren3_sa",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "15",
         "petr4_sa",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "16",
         "prio3_sa",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "17",
         "pssa3_sa",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "18",
         "rail3_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "19",
         "rdor3_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "20",
         "sbsp3_sa",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "21",
         "suzb3_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "22",
         "taee11_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "23",
         "tims3_sa",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "24",
         "tnx",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "25",
         "tots3_sa",
         "2025-09-29 00:00:00-03:00",
         "2025-09-29"
        ],
        [
         "26",
         "ugpa3_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "27",
         "vale3_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "28",
         "vivt3_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ],
        [
         "30",
         "wege3_sa",
         "2025-09-26 00:00:00-03:00",
         "2025-09-26"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 28
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>max_date_iso</th>\n",
       "      <th>max_date_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abev3_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b3sa3_sa</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bbas3_sa</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bvsp</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cple6_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>csna3_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>elet3_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ewz</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ggbr4_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gspc</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hapv3_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itub4_sa</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lren3_sa</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>petr4_sa</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>prio3_sa</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pssa3_sa</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rail3_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rdor3_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sbsp3_sa</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>suzb3_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>taee11_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tims3_sa</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tnx</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tots3_sa</td>\n",
       "      <td>2025-09-29 00:00:00-03:00</td>\n",
       "      <td>2025-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ugpa3_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>vale3_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vivt3_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>wege3_sa</td>\n",
       "      <td>2025-09-26 00:00:00-03:00</td>\n",
       "      <td>2025-09-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       symbol              max_date_iso max_date_sp\n",
       "0    abev3_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "1    b3sa3_sa 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "2    bbas3_sa 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "3        bvsp 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "5    cple6_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "6    csna3_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "8    elet3_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "9         ewz 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "10   ggbr4_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "11       gspc 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "12   hapv3_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "13   itub4_sa 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "14   lren3_sa 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "15   petr4_sa 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "16   prio3_sa 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "17   pssa3_sa 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "18   rail3_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "19   rdor3_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "20   sbsp3_sa 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "21   suzb3_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "22  taee11_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "23   tims3_sa 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "24        tnx 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "25   tots3_sa 2025-09-29 00:00:00-03:00  2025-09-29\n",
       "26   ugpa3_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "27   vale3_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "28   vivt3_sa 2025-09-26 00:00:00-03:00  2025-09-26\n",
       "30   wege3_sa 2025-09-26 00:00:00-03:00  2025-09-26"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diagnóstico: quais são as max_date por símbolo (data local SP) e quem foge do cutoff?\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    by_symbol_full = pd.read_sql(text(\"\"\"\n",
    "        SELECT symbol,\n",
    "               MAX(date) AS max_date_iso\n",
    "        FROM ohlcv_daily\n",
    "        GROUP BY symbol\n",
    "        ORDER BY symbol\n",
    "    \"\"\"), conn)\n",
    "\n",
    "by_symbol_full['max_date_iso'] = pd.to_datetime(by_symbol_full['max_date_iso'], errors='coerce')\n",
    "# Extrair data local (America/Sao_Paulo) a partir do ISO com offset\n",
    "by_symbol_full['max_date_sp'] = by_symbol_full['max_date_iso'].dt.tz_convert('America/Sao_Paulo').dt.date\n",
    "\n",
    "expected = (pd.Timestamp.now(tz='America/Sao_Paulo') - pd.Timedelta(days=1)).date()\n",
    "print('Esperado (ontem SP):', expected)\n",
    "print('Distribuição de max_date_sp:')\n",
    "print(by_symbol_full['max_date_sp'].value_counts().sort_index())\n",
    "\n",
    "offenders = by_symbol_full[by_symbol_full['max_date_sp'] != expected]\n",
    "offenders"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMFrPtlHxn/1w9oMI2tL2r1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
