{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d7997f",
   "metadata": {},
   "source": [
    "# Instrução 01 — Fase 0 (dados e engenharia) — “v1-ready”\n",
    "\n",
    "## Objetivo da etapa\n",
    "\n",
    "Produzir um dataset único “v1-ready” para todos os tickers (Close+Volume + regime IBOV), com:\n",
    "\n",
    "* saneamento básico,\n",
    "* features adicionais mínimas do Plano v1,\n",
    "* targets de treino (D_t e U_t),\n",
    "* sem CLV,\n",
    "* sem vazamento temporal.\n",
    "\n",
    "## Entradas (obrigatórias)\n",
    "\n",
    "* Arquivo base: `gold_rl_tabular.{csv|parquet}` contendo ao menos:\n",
    "  `date, ticker, close, volume, z1, z2, z3, z5, vol21, vol21_pct, rvol_pct, rvol_chg, med_vol21, dist_peak20_sigma, pct_z2_le_m1, ret1, ret3, ret5`.\n",
    "* Série do IBOV dentro do mesmo arquivo, identificada por `ticker == \"_BVSP\"`.\n",
    "\n",
    "## Saídas\n",
    "\n",
    "1. Arquivo consolidado “v1-ready” (mesmo diretório do input), com nome:\n",
    "\n",
    "   * `gold_rl_tabular_v1_ready.parquet` e `gold_rl_tabular_v1_ready.csv`\n",
    "2. Esquema mínimo adicional (por linha, por ticker≠_BVSP):\n",
    "\n",
    "   * `t_slope_10_logclose`, `t_slope_20_logclose`\n",
    "   * `vol21_pct_ibov` (percentil da vol 21d do IBOV, janela longa parametrizável)\n",
    "   * `dd_ibov_20d_sigma` (drawdown 20d do IBOV escalado por sigma/21d)\n",
    "   * Targets:\n",
    "\n",
    "     * `D1_min`, `D3_min`, `D5_min`  (pior retorno intrajanela em 1/3/5)\n",
    "     * `U_comp` = `1.0*ret1 + 0.6*ret3 + 0.3*ret5 - cost_entry`\n",
    "   * Flags de qualidade: `flag_imputed`, `flag_window_warmup`\n",
    "3. Relatório de controle (stdout): contagens por ticker, datas min/max, % de linhas removidas por regra.\n",
    "\n",
    "## Critérios de aceitação (Go/No-Go)\n",
    "\n",
    "* Nenhuma linha com `close<=0` ou `volume<=0` permanece.\n",
    "* Não há NaN em colunas derivadas fora dos períodos de warmup de janelas (esses devem estar marcados com flags e/ou excluídos de treino).\n",
    "* `_BVSP` **não** aparece nas linhas de saída (fica só como fonte para features de regime).\n",
    "* Amostras de `t_slope_10/20`, `vol21_pct_ibov`, `dd_ibov_20d_sigma`, `D*_min`, `U_comp` são coerentes (valores não degenerados).\n",
    "* Tamanhos finais por ticker e período batem com o calendário de pregão, salvo cortes do warmup.\n",
    "\n",
    "## Parametrizações (fixe em constantes no topo)\n",
    "\n",
    "* `W_TREND = [10, 20]` (slopes no log-close).\n",
    "* `W_VOL_PCTL = 252` (janela longa para percentil de vol do IBOV; se insuficiente, use 126).\n",
    "* `W_DD = 20`, `W_SIGMA = 21` (DD 20d, sigma/21d para escalonamento).\n",
    "* `COST_ENTRY_BPS = 25` (custo de entrada para `U_comp`; manter igual ao Plano v1).\n",
    "* `EXCLUDE_ZEROES = True` (remove close/volume ≤ 0).\n",
    "* `DROP_CLV = True`.\n",
    "\n",
    "## Regras de implementação (sem vazamento)\n",
    "\n",
    "1. **Slopes de tendência**: transformar `close` em `log_close`; para cada janela `w∈{10,20}`, regressão linear simples de `log_close` em `t` (0..w-1) **usando somente passado**; salvar o coeficiente (slope/dia).\n",
    "2. **Volatilidade do IBOV (21d) e percentil**:\n",
    "\n",
    "   * Em `_BVSP`, calcule retorno diário `r_ibov = log(close_t/close_{t-1})`.\n",
    "   * `vol21_ibov = std(r_ibov, janela=21)` (rolling, passado).\n",
    "   * `vol21_pct_ibov = percent_rank(vol21_ibov, janela=W_VOL_PCTL)` (passado).\n",
    "3. **Drawdown IBOV 20d escalado**:\n",
    "\n",
    "   * Em `_BVSP`, para cada dia t, compute o **máximo** de `close` nos últimos `W_DD` dias (incluindo t), e o **mínimo subsequente até t`**? Aqui, como feature contemporânea sem lookahead: use `dd_ibov_20d = (close_t / rolling_max(close, W_DD) - 1)`.\n",
    "   * Escale por `sigma_ibov = rolling_std(r_ibov, W_SIGMA)`;\n",
    "     `dd_ibov_20d_sigma = dd_ibov_20d / sigma_ibov`.\n",
    "4. **Propagar features do IBOV** para as linhas dos demais tickers por `date` (join por data).\n",
    "5. **Targets**: para cada ticker≠_BVSP:\n",
    "\n",
    "   * `D_h_min` (h∈{1,3,5}): pior retorno intrajanela em horizonte h contado **à frente**:\n",
    "     `D_h_min(t) = min_{k=1..h} (close_{t+k}/close_t - 1)`; ignorar dias com janela incompleta.\n",
    "   * `U_comp = 1.0*ret1 + 0.6*ret3 + 0.3*ret5 - COST_ENTRY_BPS/10000`.\n",
    "6. **Saneamento**:\n",
    "\n",
    "   * Se `EXCLUDE_ZEROES`: descartar linhas com `close<=0` ou `volume<=0`.\n",
    "   * Linhas afetadas por warmup de janelas (slopes, vol, percentil, DD, targets) devem receber `flag_window_warmup=1`; opcionalmente, exclua-as do treino nas próximas fases.\n",
    "7. **Retirar CLV**: se existir coluna `clv`, removê-la do output.\n",
    "\n",
    "## Checklist de validação (imprimir no final)\n",
    "\n",
    "* Linhas finais, por ticker e total.\n",
    "* Datas min/max por ticker.\n",
    "* % de linhas excluídas por zero/negativo.\n",
    "* % de linhas marcadas como `flag_window_warmup`.\n",
    "* Amostra (5 linhas) de cada nova coluna derivada.\n",
    "* Confirmação de que `_BVSP` não está no output final.\n",
    "\n",
    "## Telemetria mínima (stdout)\n",
    "\n",
    "* `CHECKLIST_OK` ou `CHECKLIST_FAILURE` com motivos.\n",
    "* Se falhar, listar as chaves que falharam e parar.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6056720a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFIG]\n",
      "{'W_TREND': [10, 20], 'W_VOL_PCTL': 252, 'W_DD': 20, 'W_SIGMA': 21, 'COST_ENTRY_BPS': 25, 'EXCLUDE_ZEROES': True, 'DROP_CLV': True}\n"
     ]
    }
   ],
   "source": [
    "# Imports, constants, and notebook settings\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.width\", 160)\n",
    "pd.set_option(\"display.max_columns\", 60)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# ---- Parameters (Plano v1) ----\n",
    "W_TREND = [10, 20]              # slopes on log-close\n",
    "W_VOL_PCTL = 252                # long window for IBOV vol percentile (fallback to 126 if insufficient)\n",
    "W_DD = 20                       # drawdown lookback\n",
    "W_SIGMA = 21                    # sigma window for scaling\n",
    "COST_ENTRY_BPS = 25             # entry cost (bps)\n",
    "EXCLUDE_ZEROES = True           # drop rows with close<=0 or volume<=0\n",
    "DROP_CLV = True                 # drop 'clv' column if present\n",
    "\n",
    "# Derived\n",
    "COST_ENTRY = COST_ENTRY_BPS / 10000.0\n",
    "\n",
    "# Globals (filled during run)\n",
    "INPUT_FILE: Optional[Path] = None\n",
    "INPUT_DIR: Optional[Path] = None\n",
    "TOTAL_ROWS: int = 0\n",
    "REMOVED_ZERO_NEG: int = 0\n",
    "\n",
    "print(\"[CONFIG]\")\n",
    "print({\n",
    "    \"W_TREND\": W_TREND,\n",
    "    \"W_VOL_PCTL\": W_VOL_PCTL,\n",
    "    \"W_DD\": W_DD,\n",
    "    \"W_SIGMA\": W_SIGMA,\n",
    "    \"COST_ENTRY_BPS\": COST_ENTRY_BPS,\n",
    "    \"EXCLUDE_ZEROES\": EXCLUDE_ZEROES,\n",
    "    \"DROP_CLV\": DROP_CLV,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a295ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional input path override (set to a string path or leave as None)\n",
    "# Example: r\"G:\\\\Drives compartilhados\\\\BOLSA_2026\\\\a_bolsa2026_gemini\\\\00_data\\\\03_final\\\\gold_rl_tabular.parquet\"\n",
    "INPUT_FILE_OVERRIDE: Optional[str] = r\"G:\\Drives compartilhados\\BOLSA_2026\\a_bolsa2026_gemini\\00_data\\03_final\\gold_rl_tabular.parquet\"  # or set via env GOLD_RL_TABULAR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0972c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: loading, rolling slope, percent rank, telemetry\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "def find_input_file(preferred_dir: Optional[Path] = None) -> Path:\n",
    "    # Honor explicit override via variable or environment\n",
    "    override = INPUT_FILE_OVERRIDE or os.environ.get(\"GOLD_RL_TABULAR_PATH\")\n",
    "    if override:\n",
    "        p = Path(override)\n",
    "        if p.exists():\n",
    "            return p\n",
    "        raise FileNotFoundError(f\"Override path not found: {p}\")\n",
    "\n",
    "    candidates = []\n",
    "    search_dirs = [preferred_dir] if preferred_dir else []\n",
    "    # default search path: project root's 00_data/03_final first, then 00_data/02_curado, then repo root\n",
    "    root = Path.cwd()\n",
    "    for p in [root / \"00_data\" / \"03_final\", root / \"00_data\" / \"02_curado\", root]:\n",
    "        if p.exists():\n",
    "            search_dirs.append(p)\n",
    "    for d in search_dirs:\n",
    "        candidates.extend([\n",
    "            d / \"gold_rl_tabular.parquet\",\n",
    "            d / \"gold_rl_tabular.csv\",\n",
    "        ])\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            return c\n",
    "    raise FileNotFoundError(\"gold_rl_tabular.{parquet|csv} not found in default locations. Set INPUT_FILE_OVERRIDE or env GOLD_RL_TABULAR_PATH.\")\n",
    "\n",
    "\n",
    "def read_base_file(path: Path) -> pd.DataFrame:\n",
    "    if path.suffix.lower() == \".parquet\":\n",
    "        return pd.read_parquet(path)\n",
    "    if path.suffix.lower() == \".csv\":\n",
    "        return pd.read_csv(path)\n",
    "    raise ValueError(f\"Unsupported extension: {path.suffix}\")\n",
    "\n",
    "\n",
    "def ensure_datetime(df: pd.DataFrame, date_col: str = \"date\") -> pd.DataFrame:\n",
    "    if not np.issubdtype(df[date_col].dtype, np.datetime64):\n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "    return df\n",
    "\n",
    "\n",
    "def percent_rank_rolling(s: pd.Series, window: int) -> pd.Series:\n",
    "    # Rolling percent rank: position of last element within the window\n",
    "    def pr(x: pd.Series) -> float:\n",
    "        v = x.iloc[-1]\n",
    "        if not np.isfinite(v):\n",
    "            return np.nan\n",
    "        x_valid = x[np.isfinite(x)]\n",
    "        if len(x_valid) == 0:\n",
    "            return np.nan\n",
    "        return (x_valid <= v).mean()\n",
    "    return s.rolling(window, min_periods=window).apply(pr, raw=False)\n",
    "\n",
    "\n",
    "def rolling_slope(series: pd.Series, window: int) -> pd.Series:\n",
    "    # linear regression slope of y ~ t for t=0..w-1 using only past values\n",
    "    # returns slope per day\n",
    "    y = series\n",
    "    idx = np.arange(window)\n",
    "    # Precompute design stats\n",
    "    x_mean = idx.mean()\n",
    "    ssx = ((idx - x_mean) ** 2).sum()\n",
    "\n",
    "    def slope_last_w(x: np.ndarray) -> float:\n",
    "        if np.any(~np.isfinite(x)):\n",
    "            return np.nan\n",
    "        y_mean = x.mean()\n",
    "        cov = ((idx - x_mean) * (x - y_mean)).sum()\n",
    "        return cov / ssx if ssx != 0 else np.nan\n",
    "\n",
    "    return (\n",
    "        y.rolling(window=window, min_periods=window)\n",
    "        .apply(lambda arr: slope_last_w(arr), raw=True)\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Checklist:\n",
    "    removed_zero_neg: int = 0\n",
    "    total_rows_initial: int = 0\n",
    "    warmup_count: int = 0\n",
    "    final_rows: int = 0\n",
    "\n",
    "    def report(self):\n",
    "        pct_removed = (self.removed_zero_neg / self.total_rows_initial * 100.0) if self.total_rows_initial else 0.0\n",
    "        print(\"[CHECKLIST]\")\n",
    "        print({\n",
    "            \"removed_zero_or_negative\": self.removed_zero_neg,\n",
    "            \"pct_removed\": round(pct_removed, 4),\n",
    "            \"warmup_flagged\": self.warmup_count,\n",
    "            \"final_rows\": self.final_rows,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cf9c8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IO] Input file: G:\\Drives compartilhados\\BOLSA_2026\\a_bolsa2026_gemini\\00_data\\03_final\\gold_rl_tabular.parquet\n",
      "[IO] Loaded rows: 105089\n",
      "[CLEAN] Removed non-positive close/volume rows: 12466\n"
     ]
    }
   ],
   "source": [
    "# Load dataset, basic sanitation, and base metrics\n",
    "\n",
    "# Locate and read base file\n",
    "INPUT_FILE = find_input_file()\n",
    "INPUT_DIR = INPUT_FILE.parent\n",
    "print(f\"[IO] Input file: {INPUT_FILE}\")\n",
    "\n",
    "# Read\n",
    "base = read_base_file(INPUT_FILE)\n",
    "TOTAL_ROWS = len(base)\n",
    "print(f\"[IO] Loaded rows: {TOTAL_ROWS}\")\n",
    "\n",
    "# Ensure required columns exist\n",
    "required_cols = [\n",
    "    \"date\", \"ticker\", \"close\", \"volume\",\n",
    "    \"z1\", \"z2\", \"z3\", \"z5\", \"vol21\", \"vol21_pct\",\n",
    "    \"rvol_pct\", \"rvol_chg\", \"med_vol21\", \"dist_peak20_sigma\",\n",
    "    \"pct_z2_le_m1\", \"ret1\", \"ret3\", \"ret5\",\n",
    "]\n",
    "missing = [c for c in required_cols if c not in base.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# Basic coercions\n",
    "base = ensure_datetime(base, \"date\")\n",
    "base = base.sort_values([\"ticker\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "# Saneamento: remove close<=0 or volume<=0\n",
    "if EXCLUDE_ZEROES:\n",
    "    mask = (base[\"close\"] <= 0) | (base[\"volume\"] <= 0)\n",
    "    REMOVED_ZERO_NEG = int(mask.sum())\n",
    "    base = base.loc[~mask].copy()\n",
    "    print(f\"[CLEAN] Removed non-positive close/volume rows: {REMOVED_ZERO_NEG}\")\n",
    "\n",
    "# Split IBOV and others (case-insensitive match for '_bvsp')\n",
    "ibov_mask = base[\"ticker\"].astype(str).str.lower().eq(\"_bvsp\")\n",
    "ibov = base.loc[ibov_mask, [\"date\", \"ticker\", \"close\"]].copy()\n",
    "others = base.loc[~ibov_mask].copy()\n",
    "\n",
    "# Precompute per-ticker log_close\n",
    "others[\"log_close\"] = np.log(others[\"close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e9b5e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IBOV] Features prepared: ['date', 'vol21_pct_ibov', 'dd_ibov_20d_sigma'] ; rows: 3407 ; non-null: {'date': 3407, 'vol21_pct_ibov': 3386, 'dd_ibov_20d_sigma': 3386}\n"
     ]
    }
   ],
   "source": [
    "# IBOV features: r_ibov, vol21_ibov, vol21_pct_ibov, dd_ibov_20d_sigma\n",
    "\n",
    "# Re-load raw base to compute IBOV features without volume filtering (avoid degeneracy)\n",
    "_base_raw = read_base_file(INPUT_FILE)\n",
    "_base_raw = ensure_datetime(_base_raw, \"date\")\n",
    "ibov = _base_raw.loc[_base_raw[\"ticker\"].astype(str).str.lower().eq(\"_bvsp\"), [\"date\", \"ticker\", \"close\"]].copy()\n",
    "# Keep only positive close for IBOV\n",
    "ibov = ibov.loc[ibov[\"close\"] > 0].sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# Compute r_ibov (log returns)\n",
    "ibov[\"r_ibov\"] = np.log(ibov[\"close\"]).diff()\n",
    "\n",
    "# Rolling vol 21d (past only)\n",
    "ibov[\"vol21_ibov\"] = (\n",
    "    ibov[\"r_ibov\"].rolling(window=21, min_periods=21).std()\n",
    ")\n",
    "\n",
    "# Percentile rank over long window (W_VOL_PCTL with fallback)\n",
    "win_pctl = W_VOL_PCTL\n",
    "if len(ibov) < W_VOL_PCTL:\n",
    "    win_pctl = min(126, len(ibov)) if len(ibov) >= 126 else len(ibov)\n",
    "    if win_pctl < 2:\n",
    "        win_pctl = 2\n",
    "ibov[\"vol21_pct_ibov\"] = percent_rank_rolling(ibov[\"vol21_ibov\"], window=win_pctl)\n",
    "\n",
    "# Drawdown over last W_DD days (current vs rolling max), scaled by sigma over W_SIGMA\n",
    "roll_max = ibov[\"close\"].rolling(window=W_DD, min_periods=W_DD).max()\n",
    "ibov[\"dd_ibov_20d\"] = ibov[\"close\"] / roll_max - 1.0\n",
    "ibov[\"sigma_ibov\"] = ibov[\"r_ibov\"].rolling(window=W_SIGMA, min_periods=W_SIGMA).std()\n",
    "ibov[\"dd_ibov_20d_sigma\"] = ibov[\"dd_ibov_20d\"] / ibov[\"sigma_ibov\"]\n",
    "\n",
    "# Keep only date + needed columns for join\n",
    "ibov_feat = ibov[[\"date\", \"vol21_pct_ibov\", \"dd_ibov_20d_sigma\"]].copy()\n",
    "print(\"[IBOV] Features prepared:\", ibov_feat.columns.tolist(), \"; rows:\", len(ibov_feat), \"; non-null:\", ibov_feat.notna().sum().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e170f188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_40888\\368269613.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby(\"ticker\", group_keys=False).apply(\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_40888\\368269613.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby(\"ticker\", group_keys=False).apply(\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_40888\\368269613.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby(\"ticker\", group_keys=False).apply(\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_40888\\368269613.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby(\"ticker\", group_keys=False).apply(\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_40888\\368269613.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby(\"ticker\", group_keys=False).apply(\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_40888\\368269613.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby(\"ticker\", group_keys=False).apply(\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_40888\\368269613.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby(\"ticker\", group_keys=False).apply(\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_40888\\368269613.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby(\"ticker\", group_keys=False).apply(\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_40888\\368269613.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby(\"ticker\", group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Join IBOV features to others; compute slopes, targets, and flags\n",
    "\n",
    "# Join by date\n",
    "df = others.merge(ibov_feat, on=\"date\", how=\"left\")\n",
    "\n",
    "# Compute trend slopes on log_close per ticker\n",
    "for w in W_TREND:\n",
    "    col = f\"t_slope_{w}_logclose\"\n",
    "    df[col] = (\n",
    "        df.sort_values([\"ticker\", \"date\"])  # ensure order\n",
    "          .groupby(\"ticker\", group_keys=False)[\"log_close\"]\n",
    "          .apply(lambda s: rolling_slope(s, window=w))\n",
    "    )\n",
    "\n",
    "# Targets: worst forward return within horizon h in {1,3,5}\n",
    "# D_h_min(t) = min_{k=1..h} (close_{t+k}/close_t - 1)\n",
    "# We'll compute via groupby + shifting close\n",
    "\n",
    "for h in [1, 3, 5]:\n",
    "    future_rets = []\n",
    "    for k in range(1, h + 1):\n",
    "        future_rets.append(\n",
    "            df.groupby(\"ticker\", group_keys=False).apply(\n",
    "                lambda g, kk=k: g[\"close\"].shift(-kk) / g[\"close\"] - 1.0\n",
    "            )\n",
    "        )\n",
    "    stacked = pd.concat(future_rets, axis=1)\n",
    "    df[f\"D{h}_min\"] = stacked.min(axis=1)\n",
    "\n",
    "# U_comp = 1.0*ret1 + 0.6*ret3 + 0.3*ret5 - COST_ENTRY\n",
    "# Use existing ret1/ret3/ret5 in the dataset\n",
    "if not set([\"ret1\", \"ret3\", \"ret5\"]).issubset(df.columns):\n",
    "    raise ValueError(\"ret1/ret3/ret5 not found in base columns.\")\n",
    "\n",
    "df[\"U_comp\"] = 1.0 * df[\"ret1\"] + 0.6 * df[\"ret3\"] + 0.3 * df[\"ret5\"] - COST_ENTRY\n",
    "\n",
    "# Flags: warmup and imputed\n",
    "# Warmup where any newly created rolling value is NaN because of insufficient history\n",
    "warmup_cols = [\n",
    "    *(f\"t_slope_{w}_logclose\" for w in W_TREND),\n",
    "    \"vol21_pct_ibov\",\n",
    "    \"dd_ibov_20d_sigma\",\n",
    "    \"D1_min\", \"D3_min\", \"D5_min\",\n",
    "    # Treat missing ret horizons as warmup as well (ensures U_comp non-NaN outside warmup)\n",
    "    \"ret1\", \"ret3\", \"ret5\",\n",
    "]\n",
    "\n",
    "df[\"flag_window_warmup\"] = df[warmup_cols].isna().any(axis=1).astype(int)\n",
    "\n",
    "# No explicit imputation here; placeholder flag 0\n",
    "# (If later we impute, set 1 accordingly.)\n",
    "df[\"flag_imputed\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cce5222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IO] Wrote: G:\\Drives compartilhados\\BOLSA_2026\\a_bolsa2026_gemini\\00_data\\03_final\\gold_rl_tabular_v1_ready.parquet\n",
      "[IO] Wrote: G:\\Drives compartilhados\\BOLSA_2026\\a_bolsa2026_gemini\\00_data\\03_final\\gold_rl_tabular_v1_ready.csv\n",
      "[SUMMARY] Per-ticker counts and date ranges\n",
      "                rows   date_min   date_max\n",
      "ticker                                    \n",
      "ABEV3.SA        3400 2012-01-02 2025-10-01\n",
      "B3SA3.SA        3402 2012-01-02 2025-10-01\n",
      "BBAS3.SA        3400 2012-01-02 2025-10-01\n",
      "CPLE6.SA        3398 2012-01-02 2025-10-01\n",
      "CSNA3.SA        3397 2012-01-02 2025-10-01\n",
      "ELET3.SA        3396 2012-01-02 2025-10-01\n",
      "GGBR4.SA        3379 2012-01-02 2025-10-01\n",
      "HAPV3.SA        1845 2018-04-26 2025-10-01\n",
      "ITUB4.SA        3388 2012-01-02 2025-10-01\n",
      "LREN3.SA        3395 2012-01-02 2025-10-01\n",
      "PETR4.SA        3396 2012-01-02 2025-10-01\n",
      "PRIO3.SA        3380 2012-01-02 2025-10-01\n",
      "PSSA3.SA        3400 2012-01-02 2025-10-01\n",
      "RAIL3.SA        2595 2015-04-02 2025-10-01\n",
      "RDOR3.SA        1193 2020-12-15 2025-10-01\n",
      "SBSP3.SA        3393 2012-01-02 2025-10-01\n",
      "SUZB3.SA        1956 2017-11-10 2025-10-01\n",
      "TAEE11.SA       3383 2012-01-03 2025-10-01\n",
      "TIMS3.SA        3398 2012-01-02 2025-10-01\n",
      "TOTS3.SA        3400 2012-01-02 2025-10-01\n",
      "UGPA3.SA        3399 2012-01-02 2025-10-01\n",
      "VALE3.SA        3398 2012-01-02 2025-10-01\n",
      "VIVT3.SA        3398 2012-01-02 2025-10-01\n",
      "WEGE3.SA        3400 2012-01-02 2025-10-01\n",
      "_gspc           3455 2012-01-03 2025-09-30\n",
      "bz=f            3428 2012-01-03 2025-09-30\n",
      "dx-y.nyb           2 2015-01-22 2015-01-27\n",
      "ewz             3456 2012-01-03 2025-09-30\n",
      "is_trading_day  3417 2012-01-02 2025-10-01\n",
      "[CHECKLIST]\n",
      "{'removed_zero_or_negative': 12466, 'pct_removed': 11.8623, 'warmup_flagged': 1476, 'final_rows': 89247}\n",
      "[CHECKLIST-DETAILS]\n",
      "{'%_removed_zero_neg': 11.8623, '%_warmup_flagged': np.float64(1.6538)}\n",
      "[SAMPLES]\n",
      "               ticker       date  t_slope_10_logclose  t_slope_20_logclose  vol21_pct_ibov  dd_ibov_20d_sigma    D1_min    D3_min    D5_min  U_comp  \\\n",
      "0            ABEV3.SA 2012-01-02                  NaN                  NaN             NaN                NaN -0.011397 -0.053493 -0.057721     NaN   \n",
      "1            ABEV3.SA 2012-01-03                  NaN                  NaN             NaN                NaN -0.023243 -0.044998 -0.051692     NaN   \n",
      "2            ABEV3.SA 2012-01-04                  NaN                  NaN             NaN                NaN -0.019798 -0.024177 -0.029126     NaN   \n",
      "3            ABEV3.SA 2012-01-05                  NaN                  NaN             NaN                NaN -0.002525 -0.009517 -0.009517     NaN   \n",
      "4            ABEV3.SA 2012-01-06                  NaN                  NaN             NaN                NaN -0.001947 -0.007010 -0.007010     NaN   \n",
      "...               ...        ...                  ...                  ...             ...                ...       ...       ...       ...     ...   \n",
      "85830  is_trading_day 2012-01-02                  NaN                  NaN             NaN                NaN  0.000000  0.000000  0.000000     NaN   \n",
      "85831  is_trading_day 2012-01-03                  NaN                  NaN             NaN                NaN  0.000000  0.000000  0.000000     NaN   \n",
      "85832  is_trading_day 2012-01-04                  NaN                  NaN             NaN                NaN  0.000000  0.000000  0.000000     NaN   \n",
      "85833  is_trading_day 2012-01-05                  NaN                  NaN             NaN                NaN  0.000000  0.000000  0.000000     NaN   \n",
      "85834  is_trading_day 2012-01-06                  NaN                  NaN             NaN                NaN  0.000000  0.000000  0.000000     NaN   \n",
      "\n",
      "       flag_window_warmup  \n",
      "0                       1  \n",
      "1                       1  \n",
      "2                       1  \n",
      "3                       1  \n",
      "4                       1  \n",
      "...                   ...  \n",
      "85830                   1  \n",
      "85831                   1  \n",
      "85832                   1  \n",
      "85833                   1  \n",
      "85834                   1  \n",
      "\n",
      "[142 rows x 11 columns]\n",
      "CHECKLIST_OK\n"
     ]
    }
   ],
   "source": [
    "# Finalize: drop CLV, exclude IBOV rows (case-insensitive), write outputs, and validation checklist\n",
    "\n",
    "# Remove CLV if requested\n",
    "if DROP_CLV and \"clv\" in df.columns:\n",
    "    df = df.drop(columns=[\"clv\"])  # remove CLV from output\n",
    "\n",
    "# Exclude IBOV from output (case-insensitive)\n",
    "out_df = df.loc[~df[\"ticker\"].astype(str).str.lower().eq(\"_bvsp\")].copy()\n",
    "\n",
    "# Determine warmup rows to exclude from training (kept here but flagged)\n",
    "check = Checklist(\n",
    "    removed_zero_neg=REMOVED_ZERO_NEG,\n",
    "    total_rows_initial=TOTAL_ROWS,\n",
    "    warmup_count=int(out_df[\"flag_window_warmup\"].sum()),\n",
    "    final_rows=len(out_df),\n",
    ")\n",
    "\n",
    "# Validate acceptance criteria\n",
    "fail_reasons = []\n",
    "if (out_df[\"close\"] <= 0).any() or (out_df[\"volume\"] <= 0).any():\n",
    "    fail_reasons.append(\"Found non-positive close/volume in output\")\n",
    "\n",
    "# Ensure no NaNs in derived columns outside warmup\n",
    "derived_cols = [\n",
    "    *(f\"t_slope_{w}_logclose\" for w in W_TREND),\n",
    "    \"vol21_pct_ibov\", \"dd_ibov_20d_sigma\",\n",
    "    \"D1_min\", \"D3_min\", \"D5_min\", \"U_comp\",\n",
    "]\n",
    "mask_non_warmup = out_df[\"flag_window_warmup\"].eq(0)\n",
    "for c in derived_cols:\n",
    "    if out_df.loc[mask_non_warmup, c].isna().any():\n",
    "        fail_reasons.append(f\"NaN in {c} outside warmup\")\n",
    "\n",
    "# Ensure IBOV does not appear\n",
    "if out_df[\"ticker\"].astype(str).str.lower().eq(\"_bvsp\").any():\n",
    "    fail_reasons.append(\"_BVSP present in output\")\n",
    "\n",
    "# Sample sanity checks (non-degenerate stats)\n",
    "for c in [*(f\"t_slope_{w}_logclose\" for w in W_TREND),\n",
    "          \"vol21_pct_ibov\", \"dd_ibov_20d_sigma\",\n",
    "          \"D1_min\", \"D3_min\", \"D5_min\", \"U_comp\"]:\n",
    "    if out_df[c].dropna().nunique() <= 1:\n",
    "        fail_reasons.append(f\"Degenerate values in {c}\")\n",
    "\n",
    "# Write outputs\n",
    "out_parquet = INPUT_DIR / \"gold_rl_tabular_v1_ready.parquet\"\n",
    "out_csv = INPUT_DIR / \"gold_rl_tabular_v1_ready.csv\"\n",
    "\n",
    "out_df.to_parquet(out_parquet, index=False)\n",
    "out_df.to_csv(out_csv, index=False)\n",
    "print(f\"[IO] Wrote: {out_parquet}\")\n",
    "print(f\"[IO] Wrote: {out_csv}\")\n",
    "\n",
    "# Report per ticker counts and date ranges\n",
    "print(\"[SUMMARY] Per-ticker counts and date ranges\")\n",
    "summary = out_df.groupby(\"ticker\").agg(\n",
    "    rows=(\"date\", \"size\"),\n",
    "    date_min=(\"date\", \"min\"),\n",
    "    date_max=(\"date\", \"max\"),\n",
    ")\n",
    "print(summary)\n",
    "\n",
    "# Checklist\n",
    "check.final_rows = len(out_df)\n",
    "check.report()\n",
    "\n",
    "# Additional checklist details\n",
    "pct_removed_zero_neg = (REMOVED_ZERO_NEG / TOTAL_ROWS * 100.0) if TOTAL_ROWS else 0.0\n",
    "pct_warmup = (out_df[\"flag_window_warmup\"].mean() * 100.0) if len(out_df) else 0.0\n",
    "print(\"[CHECKLIST-DETAILS]\")\n",
    "print({\n",
    "    \"%_removed_zero_neg\": round(pct_removed_zero_neg, 4),\n",
    "    \"%_warmup_flagged\": round(pct_warmup, 4),\n",
    "})\n",
    "\n",
    "# Show samples of new columns\n",
    "print(\"[SAMPLES]\")\n",
    "sample_cols = [\n",
    "    *(f\"t_slope_{w}_logclose\" for w in W_TREND),\n",
    "    \"vol21_pct_ibov\", \"dd_ibov_20d_sigma\",\n",
    "    \"D1_min\", \"D3_min\", \"D5_min\", \"U_comp\",\n",
    "    \"flag_window_warmup\",\n",
    "]\n",
    "print(out_df.sort_values([\"ticker\", \"date\"]).loc[:, [\"ticker\", \"date\", *sample_cols]].groupby(\"ticker\").head(5))\n",
    "\n",
    "# Telemetry: verdict\n",
    "if fail_reasons:\n",
    "    print(\"CHECKLIST_FAILURE\", fail_reasons)\n",
    "    raise SystemExit(f\"CHECKLIST_FAILURE: {fail_reasons}\")\n",
    "else:\n",
    "    print(\"CHECKLIST_OK\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
